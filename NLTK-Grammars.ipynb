{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0653f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "from nltk import CFG\n",
    "from nltk import PCFG\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f3847a",
   "metadata": {},
   "source": [
    "#### About\n",
    "- Implementation for sampling from probabilistic context free grammars\n",
    "\n",
    "#### Resources\n",
    "- https://lost-contact.mit.edu/afs/cs.pitt.edu/projects/nltk/docs/tutorial/pcfg/nochunks.html\n",
    "- https://docs.huihoo.com/nltk/0.9.5/en/ch07.html\n",
    "\n",
    "\n",
    "#### Todo:\n",
    "- Grammar for https://www.englishclub.com/grammar/rules.htm\n",
    "- Add meta rules that allow to gernerically add rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ce1dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sec_to_ms(s):\n",
    "    m, s = divmod(s, 60)\n",
    "    return '{:0>2} min {:.2f} sec'.format(m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c34437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Grammar():\n",
    "    def __init__(self):\n",
    "        self._G = None\n",
    "\n",
    "    def from_string(self, string):\n",
    "        self._G = PCFG.fromstring(string)\n",
    "        self._parser = nltk.ViterbiParser(self._G)\n",
    "        return self\n",
    "    \n",
    "    def sample(self, n=10):\n",
    "        #return [' '.join(self._produce(self._G, self._G.start())) for _ in range(n)]\n",
    "        return [self._produce(self._G, self._G.start()) for _ in range(n)]\n",
    "\n",
    "    def _produce(self, grammar, symbol):\n",
    "        words = []\n",
    "        productions = grammar.productions(lhs = symbol)\n",
    "        if len(productions) == 0:\n",
    "            raise Exception(\"No rules to further expand available: lhs={}\".format(symbol))\n",
    "        all_probs = [p.prob() for p in productions]\n",
    "        production = np.random.choice(productions, size=1, replace=True, p=all_probs)[0]\n",
    "        for sym in production.rhs():\n",
    "            if isinstance(sym, str):\n",
    "                words.append(sym)\n",
    "            else:\n",
    "                words.extend(self._produce(grammar, sym))\n",
    "        return words\n",
    "    \n",
    "    def is_valid(self, sentence):\n",
    "        parsed = self._parser.parse(sentence)\n",
    "        for subtree in parsed:\n",
    "            if type(subtree) == nltk.tree.ProbabilisticTree and subtree.label() == 'S':\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def get_probs(self, sentence):\n",
    "        parsed = self._parser.parse(sentence)\n",
    "        probs = []\n",
    "        for subtree in parsed:\n",
    "            if type(subtree) == nltk.tree.ProbabilisticTree and subtree.label() == 'S':\n",
    "                probs.append(subtree.prob())\n",
    "        if len(probs) > 0:\n",
    "            return probs\n",
    "        raise Exception(\"Input is not a valid sentence!\")\n",
    "    \n",
    "    def parse(self, sentence):\n",
    "        return self._parser.parse(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11783335",
   "metadata": {},
   "source": [
    "### Simple Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd18733",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = \"\"\"\n",
    "S -> A [1.0]\n",
    "A -> 'a'B [0.5] | 'b'B [0.5]\n",
    "B -> A [0.8] | 'c' [0.2]\n",
    "\"\"\"\n",
    "G = Grammar().from_string(g)\n",
    "samples = G.sample(10)\n",
    "\n",
    "for sample in samples:\n",
    "    print(\"\".join(sample))\n",
    "    assert G.is_valid(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00e82e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = \"\"\"\n",
    "S -> 'a' A [1.0]\n",
    "A -> \"a\" A [0.5] | B [0.5]\n",
    "B -> \"b\" [1.0]\n",
    "\"\"\"\n",
    "\n",
    "G = Grammar().from_string(g)\n",
    "samples = G.sample(10)\n",
    "print(samples)\n",
    "print(G.is_valid(samples[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2038ca59",
   "metadata": {},
   "source": [
    "### Ambiguous Grammars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42199f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = \"\"\"\n",
    "S -> A [0.5] | B [0.5]\n",
    "A -> 'a' [1.0]\n",
    "B -> 'a' [1.0]\n",
    "\"\"\"\n",
    "G = Grammar().from_string(g)\n",
    "samples = G.sample(10)\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0508c67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in samples:\n",
    "    print(G.is_valid(sample), G.get_probs(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0728d554",
   "metadata": {},
   "source": [
    "### Verbose Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2980db54",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = \"\"\"\n",
    "S -> SEN [1.0]\n",
    "SEN -> SE1 [0.5] | SE1 CONJ SEN [0.5]\n",
    "SE1 -> SUB PRE OBJ [1.0]\n",
    "CONJ -> 'or' [0.1] | 'and' [0.9]\n",
    "SUB -> 'A' [0.3] | 'B' [0.4] | \"C\" [0.3]\n",
    "PRE -> 'likes' [0.8] | 'does' [0.2]\n",
    "OBJ -> 'hiking' [0.2] | 'swimming' [0.8]\n",
    "\"\"\"\n",
    "\n",
    "G = Grammar().from_string(g)\n",
    "samples = G.sample(5)\n",
    "#\n",
    "for sample in samples:\n",
    "    print(\" \".join(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba1d1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate samples\n",
    "s1 = \"A does swimming\"\n",
    "s2 = \"A does B\"\n",
    "print(G.is_valid(s1.split()))\n",
    "print(G.is_valid(s2.split()))\n",
    "\n",
    "# prob of generating a sample\n",
    "print(G.get_probs(s1.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376826bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subtree in G.parse(s1.split()):\n",
    "    print(subtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaaf2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c895653",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6f3d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "G._G.productions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56d3655",
   "metadata": {},
   "source": [
    "### Another Toy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe77e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4302357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = \"\"\"\n",
    "  S -> NP VP [1.0]\n",
    "  VP -> V NP [0.5] | V NP PP [0.5]\n",
    "  V -> \"saw\" [0.5] | \"ate\" [0.5]\n",
    "  NP -> \"John\" [0.1] | \"Mary\" [0.1] | \"Bob\" [0.1] | Det N [0.3] | Det N PP [0.4]\n",
    "  Det -> \"a\" [0.25] | \"an\" [0.25] | \"the\" [0.25] | \"my\" [0.25]\n",
    "  N -> \"dog\" [0.25] | \"cat\" [0.25] | \"cookie\" [0.25] | \"park\" [0.25]\n",
    "  PP -> P NP [1.0]\n",
    "  P -> \"in\" [0.25] | \"on\" [0.25] | \"by\" [0.25] | \"with\" [0.25]\n",
    "\"\"\"\n",
    "G = Grammar().from_string(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6d84d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = G.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756faaf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sample in samples:\n",
    "    print(\" \".join(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a90a23",
   "metadata": {},
   "source": [
    "### Simple ENglish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1652a2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = \"\"\"\n",
    "S -> NP_Sg VP_Sg | NP_Pl VP_Pl\n",
    "NP -> NP_Pl      | NP_Sg\n",
    "NP_Sg ->       N_Sg | Det_Sg N_Sg | Det_Both N_Sg | Adj N_Sg | Det_Sg Adj N_Sg | Det_Both Adj N_Sg| PropN_Sg\n",
    "NP_Pl ->       N_Pl | Det_Pl N_Pl | Det_Both N_Pl | Adj N_Pl | Det_Pl Adj N_Pl | Det_Both Adj N_Pl| PropN_Pl\n",
    "VP_Sg -> IV_Pres_Sg | IV_Past     | TV_Pres_Sg    | TV_Past  | TV_Pres_Sg NP   | TV_Past NP       | Adv IV_Pres_Sg | Adv IV_Past | Adv TV_Pres_Sg NP | Adv TV_Past NP\n",
    "VP_Pl -> IV_Pres_Pl | IV_Past     | TV_Pres_Pl    | TV_Past  | TV_Pres_Pl NP   | TV_Past NP       | Adv IV_Pres_Pl | Adv IV_Past | Adv TV_Pres_Pl NP | Adv TV_Past NP\n",
    "N_Pl -> 'girls' | 'boys' | 'children' | 'cars' | 'apples' | 'dogs'\n",
    "Adj -> 'good' | 'bad' | 'beautiful' | 'innocent'\n",
    "Adv -> 'happily' | 'sadly' | 'nicely'\n",
    "N_Sg -> 'dog' | 'girl' | 'car' | 'child' | 'apple' | 'elephant'\n",
    "PropN_Sg -> 'rashmi' | 'piyumika'\n",
    "PropN_Pl -> 'they'  | 'i'\n",
    "Det_Sg -> 'this' | 'every' | 'a' | 'an'\n",
    "Det_Pl -> 'these' | 'all'\n",
    "Det_Both -> 'some' | 'the' | ' several'\n",
    "IV_Pres_Sg -> 'dissappeares' | 'walks'\n",
    "TV_Pres_Sg -> 'sees' | 'likes' |'eat'\n",
    "IV_Pres_Pl -> 'dissappear' | 'walk'\n",
    "TV_Pres_Pl ->'see' | 'like'\n",
    "IV_Past -> 'dissappeared' | 'walked'\n",
    "TV_Past -> 'saw' | 'liked' | 'ate' | 'shot'\n",
    "\"\"\"\n",
    "G = CFG.fromstring(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29229eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce(grammar, symbol):\n",
    "    words = []\n",
    "    productions = grammar.productions(lhs = symbol)\n",
    "    if len(productions) == 0:\n",
    "        raise Exception(\"No rules to further expand available: lhs={}\".format(symbol))\n",
    "        \n",
    "    production = choice(productions)\n",
    "    for sym in production.rhs():\n",
    "        if isinstance(sym, str):\n",
    "            words.append(sym)\n",
    "        else:\n",
    "            words.extend(produce(grammar, sym))\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fb8119",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(100):\n",
    "    s = produce(G, G.start())\n",
    "    print(\" \".join(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f24a6e",
   "metadata": {},
   "source": [
    "# Feature Grammars\n",
    "- http://www.nltk.org/book_1ed/ch09.html\n",
    "- https://stackoverflow.com/questions/55770861/loading-and-editing-a-cfg-file-for-grammar-parsing\n",
    "- http://www.nltk.org/howto/featgram.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2dbdb8",
   "metadata": {},
   "source": [
    "# Test Language\n",
    "\n",
    "#### Ideas\n",
    "Syntax = Semantic, there are no ambiguous expressions\n",
    "\n",
    "#### Rules\n",
    "- There can be an infinite amount of brackets\n",
    "- The each opening bracket needs a closing bracket\n",
    "- within a bracket, there can be a sentence constructed from the following rules:\n",
    "    - |b| = |a|\n",
    "    - if there is a c in the beginning, than there is a d in the end\n",
    "    - if there are two cs in the beginning, than there is an e in the end\n",
    "    - for a g in the beginning, there is a f in the end\n",
    "    - for a f in the beginning, there is a g in the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b63fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df64b6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_grammar = Path(\"data\") / \"grammar-00.pkl\"\n",
    "sample_max_len = 32\n",
    "sample_min_len = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b96fa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = \"\"\"\n",
    "S -> S S [0.2] | '(' SEN ')' [0.2] | '[' SEN ']' [0.2] | '(' S ')' [0.2] | '[' S ']' [0.2]\n",
    "SEN -> SI [0.4] | SD [0.3] | SE [0.3]\n",
    "SD -> 'c' SI 'd' [1.0]\n",
    "SE -> 'c' 'c' SI 'e' [1.0]\n",
    "SI -> 'a' B [0.25] | B 'a' [0.25] | 'b' A [0.25] | A 'b' [0.25]\n",
    "B -> SI 'b' [0.3] | 'b' SI [0.3] | 'b' [0.4]\n",
    "A -> 'a' SI [0.3] | SI 'a' [0.3] | 'a' [0.4]\n",
    "\"\"\"\n",
    "G = Grammar().from_string(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00195506",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = G.sample(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8fdf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = set([])\n",
    "\n",
    "all_samples = []\n",
    "for sample in tqdm(samples):\n",
    "    voc = voc | set(sample)\n",
    "    if len(sample) > sample_min_len and len(sample) < sample_max_len:\n",
    "        all_samples.append(\"\".join(sample))\n",
    "all_samples = list(set(all_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1805b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_samples))\n",
    "print(voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf25f31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "n_train = int(len(all_samples) * train_ratio)\n",
    "samples_train = all_samples[:n_train]\n",
    "samples_valid = all_samples[n_train:]\n",
    "print(len(samples_train))\n",
    "print(len(samples_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e78b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = {\n",
    "    \"grammar\": g,\n",
    "    \"vocabulary\": voc,\n",
    "    \"data_train\": samples_train,\n",
    "    \"data_valid\": samples_valid,\n",
    "    \"n_samples\": len(all_samples),\n",
    "    \"token_len_min\": np.min([len(s) for s in all_samples]),\n",
    "    \"token_len_max\": np.max([len(s) for s in all_samples])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea0349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(p_grammar, \"wb\") as file:\n",
    "    pickle.dump(corpus, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc5fa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c01601",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573dd733",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in all_samples[:100]:\n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75de12de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
