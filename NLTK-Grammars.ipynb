{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b435818b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "from nltk import CFG\n",
    "from nltk import PCFG\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8172fa",
   "metadata": {},
   "source": [
    "#### About\n",
    "- Implementation for sampling from probabilistic context free grammars\n",
    "\n",
    "#### Resources\n",
    "- https://lost-contact.mit.edu/afs/cs.pitt.edu/projects/nltk/docs/tutorial/pcfg/nochunks.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b08a8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sec_to_ms(s):\n",
    "    m, s = divmod(s, 60)\n",
    "    return '{:0>2} min {:.2f} sec'.format(m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95abd5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Grammar():\n",
    "    def __init__(self):\n",
    "        self._G = None\n",
    "\n",
    "    def from_string(self, string):\n",
    "        self._G = PCFG.fromstring(string)\n",
    "        self._parser = nltk.ViterbiParser(self._G)\n",
    "        return self\n",
    "    \n",
    "    def sample(self, n=10):\n",
    "        #return [' '.join(self._produce(self._G, self._G.start())) for _ in range(n)]\n",
    "        return [self._produce(self._G, self._G.start()) for _ in range(n)]\n",
    "\n",
    "    def _produce(self, grammar, symbol):\n",
    "        words = []\n",
    "        productions = grammar.productions(lhs = symbol)\n",
    "        if len(productions) == 0:\n",
    "            raise Exception(\"No rules to further expand available: lhs={}\".format(symbol))\n",
    "        all_probs = [p.prob() for p in productions]\n",
    "        production = np.random.choice(productions, size=1, replace=True, p=all_probs)[0]\n",
    "        for sym in production.rhs():\n",
    "            if isinstance(sym, str):\n",
    "                words.append(sym)\n",
    "            else:\n",
    "                words.extend(self._produce(grammar, sym))\n",
    "        return words\n",
    "    \n",
    "    def is_valid(self, sentence):\n",
    "        parsed = self._parser.parse(sentence)\n",
    "        for subtree in parsed:\n",
    "            if type(subtree) == nltk.tree.ProbabilisticTree and subtree.label() == 'S':\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def get_probs(self, sentence):\n",
    "        parsed = self._parser.parse(sentence)\n",
    "        probs = []\n",
    "        for subtree in parsed:\n",
    "            if type(subtree) == nltk.tree.ProbabilisticTree and subtree.label() == 'S':\n",
    "                probs.append(subtree.prob())\n",
    "        if len(probs) > 0:\n",
    "            return probs\n",
    "        raise Exception(\"Input is not a valid sentence!\")\n",
    "    \n",
    "    def parse(self, sentence):\n",
    "        return self._parser.parse(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ab9e33",
   "metadata": {},
   "source": [
    "### Simple Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccae2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = \"\"\"\n",
    "S -> A [1.0]\n",
    "A -> 'a'B [0.5] | 'b'B [0.5]\n",
    "B -> A [0.8] | 'c' [0.2]\n",
    "\"\"\"\n",
    "G = Grammar().from_string(g)\n",
    "samples = G.sample(10)\n",
    "\n",
    "for sample in samples:\n",
    "    print(\"\".join(sample))\n",
    "    assert G.is_valid(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06716d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = \"\"\"\n",
    "S -> 'a' A [1.0]\n",
    "A -> \"a\" A [0.5] | B [0.5]\n",
    "B -> \"b\" [1.0]\n",
    "\"\"\"\n",
    "\n",
    "G = Grammar().from_string(g)\n",
    "samples = G.sample(10)\n",
    "print(samples)\n",
    "print(G.is_valid(samples[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae627e9",
   "metadata": {},
   "source": [
    "### Ambiguous Grammars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc196d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = \"\"\"\n",
    "S -> A [0.5] | B [0.5]\n",
    "A -> 'a' [1.0]\n",
    "B -> 'a' [1.0]\n",
    "\"\"\"\n",
    "G = Grammar().from_string(g)\n",
    "samples = G.sample(10)\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe03e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in samples:\n",
    "    print(G.is_valid(sample), G.get_probs(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78087f54",
   "metadata": {},
   "source": [
    "### Verbose Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd81692",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = \"\"\"\n",
    "S -> SEN [1.0]\n",
    "SEN -> SE1 [0.5] | SE1 CONJ SEN [0.5]\n",
    "SE1 -> SUB PRE OBJ [1.0]\n",
    "CONJ -> 'or' [0.1] | 'and' [0.9]\n",
    "SUB -> 'A' [0.3] | 'B' [0.4] | \"C\" [0.3]\n",
    "PRE -> 'likes' [0.8] | 'does' [0.2]\n",
    "OBJ -> 'hiking' [0.2] | 'swimming' [0.8]\n",
    "\"\"\"\n",
    "\n",
    "G = Grammar().from_string(g)\n",
    "samples = G.sample(5)\n",
    "#\n",
    "for sample in samples:\n",
    "    print(\" \".join(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92ae58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate samples\n",
    "s1 = \"A does swimming\"\n",
    "s2 = \"A does B\"\n",
    "print(G.is_valid(s1.split()))\n",
    "print(G.is_valid(s2.split()))\n",
    "\n",
    "# prob of generating a sample\n",
    "print(G.get_probs(s1.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd937813",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subtree in G.parse(s1.split()):\n",
    "    print(subtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822250c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0b9944",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4df3274",
   "metadata": {},
   "outputs": [],
   "source": [
    "G._G.productions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad70cfd3",
   "metadata": {},
   "source": [
    "### Another Toy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f4b3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea77d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = \"\"\"\n",
    "  S -> NP VP [1.0]\n",
    "  VP -> V NP [0.5] | V NP PP [0.5]\n",
    "  V -> \"saw\" [0.5] | \"ate\" [0.5]\n",
    "  NP -> \"John\" [0.1] | \"Mary\" [0.1] | \"Bob\" [0.1] | Det N [0.3] | Det N PP [0.4]\n",
    "  Det -> \"a\" [0.25] | \"an\" [0.25] | \"the\" [0.25] | \"my\" [0.25]\n",
    "  N -> \"dog\" [0.25] | \"cat\" [0.25] | \"cookie\" [0.25] | \"park\" [0.25]\n",
    "  PP -> P NP [1.0]\n",
    "  P -> \"in\" [0.25] | \"on\" [0.25] | \"by\" [0.25] | \"with\" [0.25]\n",
    "\"\"\"\n",
    "G = Grammar().from_string(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d2aa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = G.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f83705",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sample in samples:\n",
    "    print(\" \".join(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfaff64",
   "metadata": {},
   "source": [
    "### Simple ENglish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e4946d",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = \"\"\"\n",
    "S -> NP_Sg VP_Sg | NP_Pl VP_Pl\n",
    "NP -> NP_Pl      | NP_Sg\n",
    "NP_Sg ->       N_Sg | Det_Sg N_Sg | Det_Both N_Sg | Adj N_Sg | Det_Sg Adj N_Sg | Det_Both Adj N_Sg| PropN_Sg\n",
    "NP_Pl ->       N_Pl | Det_Pl N_Pl | Det_Both N_Pl | Adj N_Pl | Det_Pl Adj N_Pl | Det_Both Adj N_Pl| PropN_Pl\n",
    "VP_Sg -> IV_Pres_Sg | IV_Past     | TV_Pres_Sg    | TV_Past  | TV_Pres_Sg NP   | TV_Past NP       | Adv IV_Pres_Sg | Adv IV_Past | Adv TV_Pres_Sg NP | Adv TV_Past NP\n",
    "VP_Pl -> IV_Pres_Pl | IV_Past     | TV_Pres_Pl    | TV_Past  | TV_Pres_Pl NP   | TV_Past NP       | Adv IV_Pres_Pl | Adv IV_Past | Adv TV_Pres_Pl NP | Adv TV_Past NP\n",
    "N_Pl -> 'girls' | 'boys' | 'children' | 'cars' | 'apples' | 'dogs'\n",
    "Adj -> 'good' | 'bad' | 'beautiful' | 'innocent'\n",
    "Adv -> 'happily' | 'sadly' | 'nicely'\n",
    "N_Sg -> 'dog' | 'girl' | 'car' | 'child' | 'apple' | 'elephant'\n",
    "PropN_Sg -> 'rashmi' | 'piyumika'\n",
    "PropN_Pl -> 'they'  | 'i'\n",
    "Det_Sg -> 'this' | 'every' | 'a' | 'an'\n",
    "Det_Pl -> 'these' | 'all'\n",
    "Det_Both -> 'some' | 'the' | ' several'\n",
    "IV_Pres_Sg -> 'dissappeares' | 'walks'\n",
    "TV_Pres_Sg -> 'sees' | 'likes' |'eat'\n",
    "IV_Pres_Pl -> 'dissappear' | 'walk'\n",
    "TV_Pres_Pl ->'see' | 'like'\n",
    "IV_Past -> 'dissappeared' | 'walked'\n",
    "TV_Past -> 'saw' | 'liked' | 'ate' | 'shot'\n",
    "\"\"\"\n",
    "G = CFG.fromstring(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bdeed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce(grammar, symbol):\n",
    "    words = []\n",
    "    productions = grammar.productions(lhs = symbol)\n",
    "    if len(productions) == 0:\n",
    "        raise Exception(\"No rules to further expand available: lhs={}\".format(symbol))\n",
    "        \n",
    "    production = choice(productions)\n",
    "    for sym in production.rhs():\n",
    "        if isinstance(sym, str):\n",
    "            words.append(sym)\n",
    "        else:\n",
    "            words.extend(produce(grammar, sym))\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bd8cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(100):\n",
    "    s = produce(G, G.start())\n",
    "    print(\" \".join(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364629da",
   "metadata": {},
   "source": [
    "# Feature Grammars\n",
    "- https://stackoverflow.com/questions/55770861/loading-and-editing-a-cfg-file-for-grammar-parsing\n",
    "- http://www.nltk.org/howto/featgram.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0c083b",
   "metadata": {},
   "outputs": [],
   "source": [
    "http://www.nltk.org/howto/featgram.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eab1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "g "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
