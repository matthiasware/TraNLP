{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "from nltk import CFG\n",
    "from nltk import PCFG\n",
    "import numpy as np\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About\n",
    "- Implementation for sampling from probabilistic context free grammars\n",
    "\n",
    "#### Resources\n",
    "- https://lost-contact.mit.edu/afs/cs.pitt.edu/projects/nltk/docs/tutorial/pcfg/nochunks.html\n",
    "- https://docs.huihoo.com/nltk/0.9.5/en/ch07.html\n",
    "\n",
    "\n",
    "#### Todo:\n",
    "- Grammar for https://www.englishclub.com/grammar/rules.htm\n",
    "- Add meta rules that allow to gernerically add rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sec_to_ms(s):\n",
    "    m, s = divmod(s, 60)\n",
    "    return '{:0>2} min {:.2f} sec'.format(m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Grammar():\n",
    "    def __init__(self):\n",
    "        self._G = None\n",
    "\n",
    "    def from_string(self, string):\n",
    "        self._G = PCFG.fromstring(string)\n",
    "        self._parser = nltk.ViterbiParser(self._G)\n",
    "        return self\n",
    "    \n",
    "    def sample(self, n=10):\n",
    "        #return [' '.join(self._produce(self._G, self._G.start())) for _ in range(n)]\n",
    "        return [self._produce(self._G, self._G.start()) for _ in range(n)]\n",
    "\n",
    "    def _produce(self, grammar, symbol):\n",
    "        words = []\n",
    "        productions = grammar.productions(lhs = symbol)\n",
    "        if len(productions) == 0:\n",
    "            raise Exception(\"No rules to further expand available: lhs={}\".format(symbol))\n",
    "        all_probs = [p.prob() for p in productions]\n",
    "        production = np.random.choice(productions, size=1, replace=True, p=all_probs)[0]\n",
    "        for sym in production.rhs():\n",
    "            if isinstance(sym, str):\n",
    "                words.append(sym)\n",
    "            else:\n",
    "                words.extend(self._produce(grammar, sym))\n",
    "        return words\n",
    "    \n",
    "    def is_valid(self, sentence):\n",
    "        parsed = self._parser.parse(sentence)\n",
    "        for subtree in parsed:\n",
    "            if type(subtree) == nltk.tree.ProbabilisticTree and subtree.label() == 'S':\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def get_probs(self, sentence):\n",
    "        parsed = self._parser.parse(sentence)\n",
    "        probs = []\n",
    "        for subtree in parsed:\n",
    "            if type(subtree) == nltk.tree.ProbabilisticTree and subtree.label() == 'S':\n",
    "                probs.append(subtree.prob())\n",
    "        if len(probs) > 0:\n",
    "            return probs\n",
    "        raise Exception(\"Input is not a valid sentence!\")\n",
    "    \n",
    "    def parse(self, sentence):\n",
    "        return self._parser.parse(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aabbbc\n",
      "aaaaabaabaac\n",
      "bc\n",
      "bc\n",
      "bbbc\n",
      "aabbaaac\n",
      "aaabaabbabaababc\n",
      "ac\n",
      "babababbbaaaac\n",
      "aac\n"
     ]
    }
   ],
   "source": [
    "g = \"\"\"\n",
    "S -> A [1.0]\n",
    "A -> 'a'B [0.5] | 'b'B [0.5]\n",
    "B -> A [0.8] | 'c' [0.2]\n",
    "\"\"\"\n",
    "G = Grammar().from_string(g)\n",
    "samples = G.sample(10)\n",
    "\n",
    "for sample in samples:\n",
    "    print(\"\".join(sample))\n",
    "    assert G.is_valid(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a', 'b'], ['a', 'b'], ['a', 'b'], ['a', 'a', 'b'], ['a', 'b'], ['a', 'b'], ['a', 'a', 'a', 'b'], ['a', 'a', 'a', 'a', 'a', 'a', 'b'], ['a', 'b'], ['a', 'a', 'b']]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "g = \"\"\"\n",
    "S -> 'a' A [1.0]\n",
    "A -> \"a\" A [0.5] | B [0.5]\n",
    "B -> \"b\" [1.0]\n",
    "\"\"\"\n",
    "\n",
    "G = Grammar().from_string(g)\n",
    "samples = G.sample(10)\n",
    "print(samples)\n",
    "print(G.is_valid(samples[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ambiguous Grammars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a'], ['a'], ['a'], ['a'], ['a'], ['a'], ['a'], ['a'], ['a'], ['a']]\n"
     ]
    }
   ],
   "source": [
    "g = \"\"\"\n",
    "S -> A [0.5] | B [0.5]\n",
    "A -> 'a' [1.0]\n",
    "B -> 'a' [1.0]\n",
    "\"\"\"\n",
    "G = Grammar().from_string(g)\n",
    "samples = G.sample(10)\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True [0.5]\n",
      "True [0.5]\n",
      "True [0.5]\n",
      "True [0.5]\n",
      "True [0.5]\n",
      "True [0.5]\n",
      "True [0.5]\n",
      "True [0.5]\n",
      "True [0.5]\n",
      "True [0.5]\n"
     ]
    }
   ],
   "source": [
    "for sample in samples:\n",
    "    print(G.is_valid(sample), G.get_probs(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verbose Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B likes swimming and C likes hiking\n",
      "C likes swimming\n",
      "B likes hiking\n",
      "B likes swimming or C likes swimming and C likes swimming\n",
      "C likes swimming and C likes swimming and B likes swimming\n"
     ]
    }
   ],
   "source": [
    "g = \"\"\"\n",
    "S -> SEN [1.0]\n",
    "SEN -> SE1 [0.5] | SE1 CONJ SEN [0.5]\n",
    "SE1 -> SUB PRE OBJ [1.0]\n",
    "CONJ -> 'or' [0.1] | 'and' [0.9]\n",
    "SUB -> 'A' [0.3] | 'B' [0.4] | \"C\" [0.3]\n",
    "PRE -> 'likes' [0.8] | 'does' [0.2]\n",
    "OBJ -> 'hiking' [0.2] | 'swimming' [0.8]\n",
    "\"\"\"\n",
    "\n",
    "G = Grammar().from_string(g)\n",
    "samples = G.sample(5)\n",
    "#\n",
    "for sample in samples:\n",
    "    print(\" \".join(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "[0.024]\n"
     ]
    }
   ],
   "source": [
    "# validate samples\n",
    "s1 = \"A does swimming\"\n",
    "s2 = \"A does B\"\n",
    "print(G.is_valid(s1.split()))\n",
    "print(G.is_valid(s2.split()))\n",
    "\n",
    "# prob of generating a sample\n",
    "print(G.get_probs(s1.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (SEN (SE1 (SUB A) (PRE does) (OBJ swimming)))) (p=0.024)\n"
     ]
    }
   ],
   "source": [
    "for subtree in G.parse(s1.split()):\n",
    "    print(subtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "ProbabilisticTree('S', [ProbabilisticTree('SEN', [ProbabilisticTree('SE1', [ProbabilisticTree('SUB', ['A']) (p=0.3), ProbabilisticTree('PRE', ['does']) (p=0.2), ProbabilisticTree('OBJ', ['swimming']) (p=0.8)]) (p=0.048)]) (p=0.024)]) (p=0.024)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[S -> SEN [1.0],\n",
       " SEN -> SE1 [0.5],\n",
       " SEN -> SE1 CONJ SEN [0.5],\n",
       " SE1 -> SUB PRE OBJ [1.0],\n",
       " CONJ -> 'or' [0.1],\n",
       " CONJ -> 'and' [0.9],\n",
       " SUB -> 'A' [0.3],\n",
       " SUB -> 'B' [0.4],\n",
       " SUB -> 'C' [0.3],\n",
       " PRE -> 'likes' [0.8],\n",
       " PRE -> 'does' [0.2],\n",
       " OBJ -> 'hiking' [0.2],\n",
       " OBJ -> 'swimming' [0.8]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G._G.productions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Toy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = \"\"\"\n",
    "  S -> NP VP [1.0]\n",
    "  VP -> V NP [0.5] | V NP PP [0.5]\n",
    "  V -> \"saw\" [0.5] | \"ate\" [0.5]\n",
    "  NP -> \"John\" [0.1] | \"Mary\" [0.1] | \"Bob\" [0.1] | Det N [0.3] | Det N PP [0.4]\n",
    "  Det -> \"a\" [0.25] | \"an\" [0.25] | \"the\" [0.25] | \"my\" [0.25]\n",
    "  N -> \"dog\" [0.25] | \"cat\" [0.25] | \"cookie\" [0.25] | \"park\" [0.25]\n",
    "  PP -> P NP [1.0]\n",
    "  P -> \"in\" [0.25] | \"on\" [0.25] | \"by\" [0.25] | \"with\" [0.25]\n",
    "\"\"\"\n",
    "G = Grammar().from_string(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = G.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sample in samples:\n",
    "    print(\" \".join(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple ENglish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = \"\"\"\n",
    "S -> NP_Sg VP_Sg | NP_Pl VP_Pl\n",
    "NP -> NP_Pl      | NP_Sg\n",
    "NP_Sg ->       N_Sg | Det_Sg N_Sg | Det_Both N_Sg | Adj N_Sg | Det_Sg Adj N_Sg | Det_Both Adj N_Sg| PropN_Sg\n",
    "NP_Pl ->       N_Pl | Det_Pl N_Pl | Det_Both N_Pl | Adj N_Pl | Det_Pl Adj N_Pl | Det_Both Adj N_Pl| PropN_Pl\n",
    "VP_Sg -> IV_Pres_Sg | IV_Past     | TV_Pres_Sg    | TV_Past  | TV_Pres_Sg NP   | TV_Past NP       | Adv IV_Pres_Sg | Adv IV_Past | Adv TV_Pres_Sg NP | Adv TV_Past NP\n",
    "VP_Pl -> IV_Pres_Pl | IV_Past     | TV_Pres_Pl    | TV_Past  | TV_Pres_Pl NP   | TV_Past NP       | Adv IV_Pres_Pl | Adv IV_Past | Adv TV_Pres_Pl NP | Adv TV_Past NP\n",
    "N_Pl -> 'girls' | 'boys' | 'children' | 'cars' | 'apples' | 'dogs'\n",
    "Adj -> 'good' | 'bad' | 'beautiful' | 'innocent'\n",
    "Adv -> 'happily' | 'sadly' | 'nicely'\n",
    "N_Sg -> 'dog' | 'girl' | 'car' | 'child' | 'apple' | 'elephant'\n",
    "PropN_Sg -> 'rashmi' | 'piyumika'\n",
    "PropN_Pl -> 'they'  | 'i'\n",
    "Det_Sg -> 'this' | 'every' | 'a' | 'an'\n",
    "Det_Pl -> 'these' | 'all'\n",
    "Det_Both -> 'some' | 'the' | ' several'\n",
    "IV_Pres_Sg -> 'dissappeares' | 'walks'\n",
    "TV_Pres_Sg -> 'sees' | 'likes' |'eat'\n",
    "IV_Pres_Pl -> 'dissappear' | 'walk'\n",
    "TV_Pres_Pl ->'see' | 'like'\n",
    "IV_Past -> 'dissappeared' | 'walked'\n",
    "TV_Past -> 'saw' | 'liked' | 'ate' | 'shot'\n",
    "\"\"\"\n",
    "G = CFG.fromstring(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce(grammar, symbol):\n",
    "    words = []\n",
    "    productions = grammar.productions(lhs = symbol)\n",
    "    if len(productions) == 0:\n",
    "        raise Exception(\"No rules to further expand available: lhs={}\".format(symbol))\n",
    "        \n",
    "    production = choice(productions)\n",
    "    for sym in production.rhs():\n",
    "        if isinstance(sym, str):\n",
    "            words.append(sym)\n",
    "        else:\n",
    "            words.extend(produce(grammar, sym))\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(100):\n",
    "    s = produce(G, G.start())\n",
    "    print(\" \".join(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Grammars\n",
    "- http://www.nltk.org/book_1ed/ch09.html\n",
    "- https://stackoverflow.com/questions/55770861/loading-and-editing-a-cfg-file-for-grammar-parsing\n",
    "- http://www.nltk.org/howto/featgram.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Language\n",
    "\n",
    "#### Ideas\n",
    "Syntax = Semantic, there are no ambiguous expressions\n",
    "\n",
    "#### Rules\n",
    "- There can be an infinite amount of brackets\n",
    "- The each opening bracket needs a closing bracket\n",
    "- within a bracket, there can be a sentence constructed from the following rules:\n",
    "    - |b| = |a|\n",
    "    - if there is a c in the beginning, than there is a d in the end\n",
    "    - if there are two cs in the beginning, than there is an e in the end\n",
    "    - for a g in the beginning, there is a f in the end\n",
    "    - for a f in the beginning, there is a g in the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_grammar = Path(\"data\") / \"grammar-00.pkl\"\n",
    "sample_max_len = 32\n",
    "sample_min_len = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = \"\"\"\n",
    "S -> S S [0.2] | '(' SEN ')' [0.2] | '[' SEN ']' [0.2] | '(' S ')' [0.2] | '[' S ']' [0.2]\n",
    "SEN -> SI [0.4] | SD [0.3] | SE [0.3]\n",
    "SD -> 'c' SI 'd' [1.0]\n",
    "SE -> 'c' 'c' SI 'e' [1.0]\n",
    "SI -> 'a' B [0.25] | B 'a' [0.25] | 'b' A [0.25] | A 'b' [0.25]\n",
    "B -> SI 'b' [0.3] | 'b' SI [0.3] | 'b' [0.4]\n",
    "A -> 'a' SI [0.3] | SI 'a' [0.3] | 'a' [0.4]\n",
    "\"\"\"\n",
    "G = Grammar().from_string(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = G.sample(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [00:01<00:00, 956563.01it/s]\n"
     ]
    }
   ],
   "source": [
    "voc = set([])\n",
    "\n",
    "all_samples = []\n",
    "for sample in tqdm(samples):\n",
    "    voc = voc | set(sample)\n",
    "    if len(sample) > sample_min_len and len(sample) < sample_max_len:\n",
    "        all_samples.append(\"\".join(sample))\n",
    "all_samples = list(set(all_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203403\n",
      "{'[', 'd', 'c', ')', 'b', 'e', '(', 'a', ']'}\n"
     ]
    }
   ],
   "source": [
    "print(len(all_samples))\n",
    "print(voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162722\n",
      "40681\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.8\n",
    "n_train = int(len(all_samples) * train_ratio)\n",
    "samples_train = all_samples[:n_train]\n",
    "samples_valid = all_samples[n_train:]\n",
    "print(len(samples_train))\n",
    "print(len(samples_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = {\n",
    "    \"grammar\": g,\n",
    "    \"vocabulary\": voc,\n",
    "    \"data_train\": samples_train,\n",
    "    \"data_valid\": samples_valid,\n",
    "    \"n_samples\": len(all_samples),\n",
    "    \"token_len_min\": np.min([len(s) for s in all_samples]),\n",
    "    \"token_len_max\": np.max([len(s) for s in all_samples])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(p_grammar, \"wb\") as file:\n",
    "    pickle.dump(corpus, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(', ')', '[', ']', 'a', 'b', 'c', 'd', 'e'}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203403"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ccbabbaae)[cabaabaaababbbbd]\n",
      "[(([babbabaa]))(ccaabababbe)]\n",
      "(((([ba][[[(ccabababe)]]]))))\n",
      "(babbaabbabaabbaa)\n",
      "(baab)(ccbabaabe)\n",
      "([[(ccbbaabbabaabae)]])\n",
      "([abaabb][cabbabbaad])\n",
      "[ccabe][(cbabaabbad)]\n",
      "[[[bbbabaaababbbaabaa]]]\n",
      "(baabaabaabbbba)\n",
      "(((cababd)))((ccbbaabae))(abba)\n",
      "(cbaabd)[(cababababd)]\n",
      "[([cbaabbaababd])][cababd]\n",
      "((bbabbabababaabaaabba))\n",
      "(([[cbaabd]([[ccbabababae]])]))\n",
      "(([[ccabbabae](ccbae)]))\n",
      "[((baab)[([((ccbae))])])]\n",
      "((([baabbaba])(ccabe)))\n",
      "[(ccabe)][ccabe]\n",
      "[ccbbaaababababbabbaae]\n",
      "(ab)([cababd])[cbaabbad]\n",
      "(ba)((ba))[ba]\n",
      "[caabbd](ccbaabe)\n",
      "((([[(ab)]])[((ccbae))][ab]))\n",
      "[ccbbabababaae](baba)\n",
      "[cbbaad][[ccabe]]\n",
      "([abababbabaabab])\n",
      "(ccaabbe)(ccaabbe)\n",
      "[[[(abbaba)]]](cbabaabababd)\n",
      "[aababbab][cbaabd]\n",
      "((([[bbaa]])))\n",
      "[[((([((ccbae))])[abab]))]]\n",
      "[([(ccbabababaabbabae)])]\n",
      "[ccababababe][(baab)]\n",
      "([(cbabad)](ccbaabe))\n",
      "(cbbaabad)[ccabbae]\n",
      "(abba)(baab)\n",
      "[[(cabd)]][abab]\n",
      "([((cbbaad))[([cbad])]])\n",
      "[[aaabababbb]]\n",
      "(baab)[[cbaabbabaabaabbd]]\n",
      "[[ccbabaabbabae]][[ccbbaae]]\n",
      "(([([cabd])(cbaabd)]))\n",
      "[caaabababbbabd]\n",
      "(cbabaabd)[ccabababe]\n",
      "[[babbbabaababaa]]\n",
      "([ba])[[ab]](ccbbababaae)\n",
      "[(ccababbae)[ccabe]]\n",
      "(([abababababbaab]))\n",
      "[aabbbababaabababababbaabba]\n",
      "([bababbabababaa])\n",
      "[cbad](cabbad)[ba]\n",
      "(cbabad)[(ccabe)]\n",
      "([cabd])(cbaabd)(cbabad)\n",
      "[cbabaabbabbaabbaabad]\n",
      "[([ccaabbe][ccababe])]\n",
      "(abba)[[ba]]\n",
      "(([[[ab]]([cabd])][ababab]))\n",
      "(ccabbbaae)([ccaababbaabbe])\n",
      "[baba](ccbabaabbabae)\n",
      "([[abaabb]])[(cbaabd)]\n",
      "[(cbabbaababad)](bbaa)\n",
      "((bababaabbaba))\n",
      "[[bbabaa](([[ba]]))]\n",
      "([cababaababaabbabaabbbabd])\n",
      "[aaabbabababbba]\n",
      "[[((cbad)[((([ba])))][abba])]]\n",
      "[aaababbaaabbbb]\n",
      "([abaabb](cabd))[[bababa]]\n",
      "[cabd](ccaabbe)\n",
      "[ccababbababbaaabe]\n",
      "[ccbae](caabbabaababbd)\n",
      "([(ccbbaababbaabbabaae)])\n",
      "[[[ccbbbaabbaaae]]]\n",
      "([(abababbbabbabaababaaab)])\n",
      "[((aaaababbabbabbabab)(ba))]\n",
      "(ba)[cababbabaabd]\n",
      "((ccbae))[ccabababbae]\n",
      "[baabba][ba]\n",
      "[([((([(cbbbabaabaad)])))])]\n",
      "((cababd))(cabd)\n",
      "[([(ccbbaae)])(([aabb]))]\n",
      "[([cbababaabd])](ab)\n",
      "[ab][[[((ccababe))]]]\n",
      "[(([ccaabababbabe]))]\n",
      "[cbbabaabad](abab)\n",
      "[([ba])[(ccabe)](abab)]\n",
      "((cbbaabad)(bababa))\n",
      "([(aaaabbabbb)[abba]])\n",
      "(ba)(caaabbbd)\n",
      "[abba]((ccbae))[(cabd)][cabd]\n",
      "(baaabbabbaaabb)\n",
      "[((([[([ccbabae])]])))[cabd]]\n",
      "([(caababbd)](((ccabe))))\n",
      "[[cabbad][cbbabaad]]\n",
      "[[(abba)]][[abbababababaab]]\n",
      "(ab)(cabaabbd)\n",
      "[[ccabbae]](abab)\n",
      "[[caaaaabbbbbd]]\n",
      "([ccaabbe](ccbababae))\n"
     ]
    }
   ],
   "source": [
    "for sample in all_samples[:100]:\n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
