{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d3cb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5736765",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90caab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformer.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78815e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_vocabulary = 10\n",
    "d_model = 16\n",
    "d_sentence = 8\n",
    "d_batch =  3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c925e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randint(low=0, high=d_vocabulary, size=(d_batch, d_sentence))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270fd324",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_embedding = Embedding(d_vocabulary, d_model, d_sentence)\n",
    "emb = model_embedding(x)\n",
    "#\n",
    "assert emb.shape == torch.Size((d_batch, d_sentence, d_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273e3d42",
   "metadata": {},
   "source": [
    "### Padding Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801d5d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer.utils import get_attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14389f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask without heads\n",
    "d_vocabulary = 4\n",
    "d_batch = 3\n",
    "d_sentence = 5\n",
    "\n",
    "x = torch.randint(low=0, high=d_vocabulary, size=(d_batch, d_sentence))\n",
    "mask = get_attn_mask(x)\n",
    "\n",
    "assert torch.equal(mask, (x == 0).unsqueeze(1).repeat(1, d_sentence, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5960583d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask with heads\n",
    "n_heads = 2\n",
    "d_vocabulary = 4\n",
    "d_batch = 3\n",
    "d_sentence = 5\n",
    "\n",
    "x = torch.randint(low=0, high=d_vocabulary, size=(d_batch, d_sentence))\n",
    "mask = get_attn_mask(x, n_heads=n_heads)\n",
    "\n",
    "assert mask.shape == torch.Size((d_batch, n_heads, d_sentence, d_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc84649",
   "metadata": {},
   "source": [
    "### ScaledDotProductAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0535217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformer.layers import ScaledDotProductAttention\n",
    "from transformer.utils import get_attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426c3dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# without dimension for heads\n",
    "#\n",
    "d_vocabulary = 7\n",
    "d_b = 4  # batch size\n",
    "d_k = 3  # dim of W_k\n",
    "d_v = 5  # dim of W_v\n",
    "d_l = 6  # length of sentences\n",
    "#\n",
    "Q = torch.rand((d_b, d_l, d_k))\n",
    "K = torch.rand((d_b, d_l, d_k))\n",
    "V = torch.rand((d_b, d_l, d_v))\n",
    "#\n",
    "x = torch.randint(low=0, high=d_vocabulary, size=(d_b, d_l))\n",
    "mask = get_attn_mask(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b670550",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sdpa = ScaledDotProductAttention(d_k)\n",
    "context, attn = model_sdpa(Q, K, V, mask)\n",
    "#\n",
    "assert context.shape == torch.Size((d_b, d_l, d_v))\n",
    "assert attn.shape == torch.Size((d_b, d_l, d_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3288e177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with dimensions for heads\n",
    "#\n",
    "d_vocabulary = 7\n",
    "d_b = 4  # batch size\n",
    "d_k = 3  # dim of W_k\n",
    "d_v = 5  # dim of W_v\n",
    "d_l = 6  # length of sentences\n",
    "n_h = 2  # number of heads\n",
    "#\n",
    "Q = torch.rand((d_b, n_h, d_l, d_k))\n",
    "K = torch.rand((d_b, n_h, d_l, d_k))\n",
    "V = torch.rand((d_b, n_h, d_l, d_v))\n",
    "#\n",
    "x = torch.randint(low=0, high=d_vocabulary, size=(d_b, d_l))\n",
    "mask = get_attn_mask(x, n_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9365ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sdpa = ScaledDotProductAttention(d_k)\n",
    "context, attn = model_sdpa(Q, K, V, mask)\n",
    "#\n",
    "assert context.shape == torch.Size((d_b, n_h, d_l, d_v))\n",
    "assert attn.shape == torch.Size((d_b, n_h, d_l, d_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f816827",
   "metadata": {},
   "source": [
    "### Multihead Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7c9e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer.layers import MultiHeadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c640d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_m = 8\n",
    "d_v = 8 # must be equal to d_m so far. sorry, crappy cupling of modules ;)\n",
    "#\n",
    "d_k = 6\n",
    "n_h = 2\n",
    "d_l = 7\n",
    "d_b = 3\n",
    "#\n",
    "model_mha = MultiHeadAttention(d_m, d_k, d_v, n_h)\n",
    "#\n",
    "x = torch.randint(low=0, high=d_vocabulary, size=(d_b, d_l))\n",
    "mask = get_attn_mask(x)\n",
    "\n",
    "# random embedding\n",
    "emb = torch.rand((d_b, d_l, d_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea36790e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output, attn = model_mha(emb, mask)\n",
    "#\n",
    "assert output.shape == torch.Size((d_b, d_l, d_v))\n",
    "assert attn.shape == torch.Size((d_b, n_h, d_l, d_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4173b7ae",
   "metadata": {},
   "source": [
    "### Position Wise Feed Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bb832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer.layers import PoswiseFeedForwardNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e513da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_b = 1\n",
    "d_m = 3\n",
    "d_ff = 4\n",
    "d_l = 8\n",
    "#\n",
    "x = torch.rand((d_b, d_l, d_m))\n",
    "#\n",
    "model_pffn = PoswiseFeedForwardNet(d_m, d_ff)\n",
    "#\n",
    "out = model_pffn(x)\n",
    "#\n",
    "assert out.shape == torch.Size((d_b, d_l, d_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b843b8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = 0.6\n",
    "v2 = 0.7\n",
    "#\n",
    "x = torch.rand((d_b, d_l, d_m))\n",
    "for i in range(d_l):\n",
    "    if i % 2 == 0:\n",
    "        x[0][i,:] = v1\n",
    "    else:\n",
    "        x[0][i,:] = v2\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8b1bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model_pffn(x)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6af7ef6",
   "metadata": {},
   "source": [
    "### EncoderLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05484d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformer.layers import AttentionEncoder\n",
    "from transformer.utils import get_attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3421e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_voc = 10\n",
    "d_m = d_v = 3\n",
    "d_k = 4 \n",
    "n_h = 2\n",
    "d_ff = 4 * d_m\n",
    "#\n",
    "d_l = 6\n",
    "#\n",
    "d_b = 8\n",
    "#\n",
    "x = torch.randint(low=0, high=d_voc, size=(d_b, d_l))\n",
    "mask = get_attn_mask(x)\n",
    "#\n",
    "# random embedding\n",
    "emb = torch.rand((d_b, d_l, d_m))\n",
    "#\n",
    "model_el = AttentionEncoder(d_m, d_k, d_v, n_h, d_ff)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9516df",
   "metadata": {},
   "outputs": [],
   "source": [
    "out, attn = model_el.forward(emb, mask)\n",
    "#\n",
    "assert out.shape == torch.Size((d_b, d_l, d_v))\n",
    "assert attn.shape == torch.Size((d_b, n_h, d_l, d_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e83e44",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d635890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformer.layers import Embedding, AttentionEncoder\n",
    "from transformer.utils import get_attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d265613e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "    def __init__(\n",
    "        self, d_vocab: int, d_model: int, d_sentence: int,\n",
    "        n_layers, n_heads, d_k, d_v, d_ff\n",
    "    ):\n",
    "        super(BERT, self).__init__()\n",
    "        #\n",
    "        self.d_vocab = d_vocab\n",
    "        self.d_model = d_model\n",
    "        self.d_sentence = d_sentence\n",
    "        self.n_layers = n_layers\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        self.d_ff = d_ff\n",
    "        #\n",
    "        assert self.d_v == self.d_model # not optimal but hey ...\n",
    "        \n",
    "        # Input Embeddings\n",
    "        self.embedding = Embedding(d_vocab, d_model, d_sentence)\n",
    "        \n",
    "        # Attention Layers\n",
    "        self.layers = []\n",
    "        for _ in range(n_layers):\n",
    "            layer = AttentionEncoder(d_model, d_k, d_v, n_heads, d_ff)\n",
    "            self.layers.append(layer)\n",
    "        self.layers = nn.ModuleList(self.layers)\n",
    "        \n",
    "        # Output Head\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.linear = nn.Linear(d_model, d_model)\n",
    "        self.gelu = torch.nn.GELU()\n",
    "        \n",
    "        # Output Decoder\n",
    "        #  = inverse Embedding\n",
    "        # There might be a better solution\n",
    "        self.decoder = nn.Linear(d_model, d_vocab)\n",
    "        self.decoder.weight = self.embedding.tok_emb.weight\n",
    "        self.decoder_bias = nn.Parameter(torch.zeros(d_vocab))\n",
    "    \n",
    "    \n",
    "    def forward(self, input_ids, input_mask_pos):\n",
    "        mask = get_attn_mask(input_ids)\n",
    "        out = self.embedding(input_ids)\n",
    "        for layer in self.layers:\n",
    "            out, attn = layer(out, mask)\n",
    "        \n",
    "        # [b, max_pred, d_model]\n",
    "        masked_pos = input_mask_pos[:, :, None].expand(-1, -1, out.size(-1))\n",
    "        h_masked = torch.gather(out, 1, masked_pos)\n",
    "        h_masked = self.norm(self.gelu(self.linear(h_masked)))\n",
    "        #\n",
    "        logits = self.decoder(h_masked) + self.decoder_bias\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fdbc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_vocab = 10\n",
    "d_model = d_v = 6\n",
    "d_sentence = 8\n",
    "n_layers = 4\n",
    "n_heads = 5\n",
    "d_k = 7\n",
    "d_ff = 4 * d_model\n",
    "d_batch = 2\n",
    "#\n",
    "d_pred_max = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba34dca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.randint(low=0, high=d_vocab, size=(d_batch, d_sentence))\n",
    "input_mask_pos = torch.zeros((d_batch, d_pred_max), dtype=torch.long)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        input_mask_pos[i][j] = i * 2 + j + 1\n",
    "input_mask_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26de9b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERT(d_vocab,\n",
    "             d_model,\n",
    "             d_sentence,\n",
    "             n_layers,\n",
    "             n_heads,\n",
    "             d_k,\n",
    "             d_v,\n",
    "             d_ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd84fea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.forward(input_ids, input_mask_pos)\n",
    "assert out.shape == torch.Size((d_batch, d_pred_max, d_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1699e202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c72bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0511eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
