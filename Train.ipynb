{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75cd533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f3bfa6",
   "metadata": {},
   "source": [
    "### Markdown\n",
    "- Understand gathering in last layer\n",
    "- What is my baseline?\n",
    "- What is the expected output?\n",
    "- Are there valid metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f55b369",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import pickle\n",
    "from transformer.datasets import get_specialized_vocabulary, GrammarDataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from dotted_dict import DottedDict\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from transformer.utils import count_parameters\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ce34eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DottedDict()\n",
    "config.n_vis = 16\n",
    "config.batch_size = 512     \n",
    "config.pred_min = 1      # min number of masked tokens [MSK]\n",
    "config.pred_max = 1      # max number of masked tokens\n",
    "config.pred_freq = 0.15  # number of mask tokens = pred_freq * d_l\n",
    "config.d_model = 8       # embed. dimension of tokens and positions\n",
    "config.d_k = 256           \n",
    "config.d_q = 256\n",
    "config.d_v = config.d_model\n",
    "config.d_ff = 4 * config.d_model\n",
    "config.n_heads = 16       # number of attention heads\n",
    "config.d_sentence = 32          # number of tokens in sentence\n",
    "config.n_layers = 8\n",
    "config.device = \"cuda:0\"\n",
    "config.p_data = Path(\"data\") / \"grammar-00.pkl\"\n",
    "config.n_epochs = 10\n",
    "config.lr = 0.001\n",
    "#\n",
    "config.freqs = DottedDict()\n",
    "config.freqs.print_valid_preds = 318 * 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456132fb",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a380936c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config.p_data, \"rb\") as file:\n",
    "    data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad49e76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data[\"data_train\"]\n",
    "data_valid = data[\"data_valid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a0440e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'[PAD]': 0, '[MSK]': 1, '[CLS]': 2, 'b': 3, ')': 4, 'c': 5, '[': 6, 'a': 7, ']': 8, '(': 9, 'e': 10, 'd': 11}\n"
     ]
    }
   ],
   "source": [
    "tok_dict = get_specialized_vocabulary(data[\"vocabulary\"])\n",
    "print(tok_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c32ce6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tok_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c56add87",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = GrammarDataset(data[\"data_train\"], tok_dict, d_sentence=config.d_sentence)\n",
    "ds_valid = GrammarDataset(data[\"data_valid\"], tok_dict, d_sentence=config.d_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b635153",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(ds_train, batch_size=config.batch_size, shuffle=True, num_workers=8)\n",
    "dl_valid = DataLoader(ds_valid, batch_size=config.batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa07012e",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36a2ac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformer.layers import Embedding, AttentionEncoder\n",
    "from transformer.utils import get_attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e66b5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "    def __init__(\n",
    "        self, d_vocab: int, d_model: int, d_sentence: int,\n",
    "        n_layers, n_heads, d_k, d_v, d_ff\n",
    "    ):\n",
    "        super(BERT, self).__init__()\n",
    "        #\n",
    "        self.d_vocab = d_vocab\n",
    "        self.d_model = d_model\n",
    "        self.d_sentence = d_sentence\n",
    "        self.n_layers = n_layers\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        self.d_ff = d_ff\n",
    "        #\n",
    "        assert self.d_v == self.d_model # not optimal but hey ...\n",
    "        \n",
    "        # Input Embeddings\n",
    "        self.embedding = Embedding(d_vocab, d_model, d_sentence)\n",
    "        \n",
    "        # Attention Layers\n",
    "        self.layers = []\n",
    "        for _ in range(n_layers):\n",
    "            layer = AttentionEncoder(d_model, d_k, d_v, n_heads, d_ff)\n",
    "            self.layers.append(layer)\n",
    "        self.layers = nn.ModuleList(self.layers)\n",
    "        \n",
    "        # Output Head\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.linear = nn.Linear(d_model, d_model)\n",
    "        self.gelu = torch.nn.GELU()\n",
    "        \n",
    "        # Output Decoder\n",
    "        #  = inverse Embedding\n",
    "        # There might be a better solution\n",
    "        self.decoder = nn.Linear(d_model, d_vocab)\n",
    "        self.decoder.weight = self.embedding.tok_emb.weight\n",
    "        self.decoder_bias = nn.Parameter(torch.zeros(d_vocab))\n",
    "    \n",
    "    \n",
    "    def forward(self, input_ids, input_mask_pos):\n",
    "        mask = get_attn_mask(input_ids)\n",
    "        out = self.embedding(input_ids)\n",
    "        for layer in self.layers:\n",
    "            out, attn = layer(out, mask)\n",
    "        \n",
    "        # [b, max_pred, d_model]\n",
    "        masked_pos = input_mask_pos[:, :, None].expand(-1, -1, out.size(-1))\n",
    "        h_masked = torch.gather(out, 1, masked_pos)\n",
    "        h_masked = self.norm(self.gelu(self.linear(h_masked)))\n",
    "        #\n",
    "        logits = self.decoder(h_masked) + self.decoder_bias\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ada678e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERT(d_vocab=len(tok_dict),\n",
    "             d_model=config.d_model,\n",
    "             d_sentence=config.d_sentence,\n",
    "             n_layers=config.n_layers,\n",
    "             n_heads=config.n_heads,\n",
    "             d_k=config.d_k,\n",
    "             d_v=config.d_v,\n",
    "             d_ff=config.d_ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2af73568",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51216bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Params: 612,320\n"
     ]
    }
   ],
   "source": [
    "print(\"#Params: {:,}\".format(count_parameters(model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "768f4678",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a526886",
   "metadata": {},
   "source": [
    "### Vis data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b001cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_data = next(iter(dl_valid))\n",
    "tok_list_vis, mask_idcs_vis, mask_toks_vis = next(iter(dl_valid))\n",
    "tok_list_vis = tok_list_vis[:config.n_vis]\n",
    "mask_idcs_vis = mask_idcs_vis[:config.n_vis]\n",
    "mask_toks_vis = mask_toks_vis[:config.n_vis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6490cce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(tok_list_vis.to(config.device), mask_idcs_vis.to(config.device))\n",
    "preds_vis = logits.argmax(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82af6965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_verbose_output(tok_list, mask_toks, preds, ds):\n",
    "    #\n",
    "    all_sentences = []\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    #\n",
    "    for idx in range(preds.size(0)):\n",
    "        sentence = [ds.idx_dict[tok_id.item()] for tok_id in tok_list[idx] if tok_id.item() not in (0, 2)]\n",
    "        sentence = \"\".join(sentence)\n",
    "        all_sentences.append(sentence)\n",
    "        #\n",
    "        label = ds.idx_dict[mask_toks[idx].item()]\n",
    "        pred = ds.idx_dict[preds[idx].item()]\n",
    "\n",
    "        all_labels.append(label)\n",
    "        all_predictions.append(pred)\n",
    "\n",
    "    return all_sentences, all_labels, all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5948f4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  input label pred\n",
      "0                      (ab)[a[MSK]babb]     a    b\n",
      "1                  ((ab))[MSK]((baba)))     (    b\n",
      "2              (baabababbababaabb[MSK])     a    b\n",
      "3   [ccbaabbae](([MSK][bbabaa]]))(cabd)     [    b\n",
      "4   [[(ccababababe)][(ab[MSK]]((abab))]     )    b\n",
      "5              ((ab[MSK]a)[([[cbad]])])     b    b\n",
      "6                    [MSK]cbad)[abbaab]     (    b\n",
      "7          (([cbbaabbb[MSK]aabbaabad]))     a    b\n",
      "8           ([ab][MSK][(ba)]([ccababe])     )    b\n",
      "9        [[MSK]ccaababbaabbe)(ccababe)]     (    b\n",
      "10                 [MSK]([aabb]))(baba)     (    b\n",
      "11           (cbb[MSK]babaaabbbabaabad)     a    b\n",
      "12           ((((ba))))([[[(ba)[MSK]]])     ]    b\n",
      "13        [(((ccabababbababaab[MSK])))]     e    b\n",
      "14             [(cabd)([b[MSK]bababa])]     a    b\n",
      "15         ([cabbaabd])[cb[MSK]abaabad]     b    b\n"
     ]
    }
   ],
   "source": [
    "all_sentence, all_labels, all_preds = get_verbose_output(tok_list_vis, mask_toks_vis, preds_vis, ds_valid)\n",
    "df = pd.DataFrame({'input': all_sentence, 'label': all_labels, 'pred': all_preds})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6937dd",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb51a831",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 0: 100%|██████████| 318/318 [00:56<00:00,  5.59it/s, loss=2.07]\n",
      "Train 1:   0%|          | 0/318 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  input label pred\n",
      "0                      (ab)[a[MSK]babb]     a    a\n",
      "1                  ((ab))[MSK]((baba)))     (    a\n",
      "2              (baabababbababaabb[MSK])     a    a\n",
      "3   [ccbaabbae](([MSK][bbabaa]]))(cabd)     [    a\n",
      "4   [[(ccababababe)][(ab[MSK]]((abab))]     )    a\n",
      "5              ((ab[MSK]a)[([[cbad]])])     b    a\n",
      "6                    [MSK]cbad)[abbaab]     (    (\n",
      "7          (([cbbaabbb[MSK]aabbaabad]))     a    a\n",
      "8           ([ab][MSK][(ba)]([ccababe])     )    a\n",
      "9        [[MSK]ccaababbaabbe)(ccababe)]     (    [\n",
      "10                 [MSK]([aabb]))(baba)     (    [\n",
      "11           (cbb[MSK]babaaabbbabaabad)     a    b\n",
      "12           ((((ba))))([[[(ba)[MSK]]])     ]    ]\n",
      "13        [(((ccabababbababaab[MSK])))]     e    ]\n",
      "14             [(cabd)([b[MSK]bababa])]     a    )\n",
      "15         ([cabbaabd])[cb[MSK]abaabad]     b    a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 1: 100%|██████████| 318/318 [00:57<00:00,  5.51it/s, loss=1.42]\n",
      "Train 2:   0%|          | 0/318 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  input label pred\n",
      "0                      (ab)[a[MSK]babb]     a    )\n",
      "1                  ((ab))[MSK]((baba)))     (    [\n",
      "2              (baabababbababaabb[MSK])     a    a\n",
      "3   [ccbaabbae](([MSK][bbabaa]]))(cabd)     [    [\n",
      "4   [[(ccababababe)][(ab[MSK]]((abab))]     )    a\n",
      "5              ((ab[MSK]a)[([[cbad]])])     b    b\n",
      "6                    [MSK]cbad)[abbaab]     (    [\n",
      "7          (([cbbaabbb[MSK]aabbaabad]))     a    a\n",
      "8           ([ab][MSK][(ba)]([ccababe])     )    ]\n",
      "9        [[MSK]ccaababbaabbe)(ccababe)]     (    [\n",
      "10                 [MSK]([aabb]))(baba)     (    [\n",
      "11           (cbb[MSK]babaaabbbabaabad)     a    a\n",
      "12           ((((ba))))([[[(ba)[MSK]]])     ]    ]\n",
      "13        [(((ccabababbababaab[MSK])))]     e    b\n",
      "14             [(cabd)([b[MSK]bababa])]     a    a\n",
      "15         ([cabbaabd])[cb[MSK]abaabad]     b    b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 2: 100%|██████████| 318/318 [00:57<00:00,  5.49it/s, loss=1.01]\n",
      "Train 3:   0%|          | 0/318 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  input label pred\n",
      "0                      (ab)[a[MSK]babb]     a    a\n",
      "1                  ((ab))[MSK]((baba)))     (    [\n",
      "2              (baabababbababaabb[MSK])     a    a\n",
      "3   [ccbaabbae](([MSK][bbabaa]]))(cabd)     [    b\n",
      "4   [[(ccababababe)][(ab[MSK]]((abab))]     )    )\n",
      "5              ((ab[MSK]a)[([[cbad]])])     b    b\n",
      "6                    [MSK]cbad)[abbaab]     (    (\n",
      "7          (([cbbaabbb[MSK]aabbaabad]))     a    a\n",
      "8           ([ab][MSK][(ba)]([ccababe])     )    )\n",
      "9        [[MSK]ccaababbaabbe)(ccababe)]     (    [\n",
      "10                 [MSK]([aabb]))(baba)     (    (\n",
      "11           (cbb[MSK]babaaabbbabaabad)     a    a\n",
      "12           ((((ba))))([[[(ba)[MSK]]])     ]    ]\n",
      "13        [(((ccabababbababaab[MSK])))]     e    b\n",
      "14             [(cabd)([b[MSK]bababa])]     a    a\n",
      "15         ([cabbaabd])[cb[MSK]abaabad]     b    b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 3: 100%|██████████| 318/318 [00:58<00:00,  5.47it/s, loss=0.738]\n",
      "Train 4:   0%|          | 0/318 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  input label pred\n",
      "0                      (ab)[a[MSK]babb]     a    a\n",
      "1                  ((ab))[MSK]((baba)))     (    (\n",
      "2              (baabababbababaabb[MSK])     a    a\n",
      "3   [ccbaabbae](([MSK][bbabaa]]))(cabd)     [    [\n",
      "4   [[(ccababababe)][(ab[MSK]]((abab))]     )    ]\n",
      "5              ((ab[MSK]a)[([[cbad]])])     b    b\n",
      "6                    [MSK]cbad)[abbaab]     (    (\n",
      "7          (([cbbaabbb[MSK]aabbaabad]))     a    a\n",
      "8           ([ab][MSK][(ba)]([ccababe])     )    ]\n",
      "9        [[MSK]ccaababbaabbe)(ccababe)]     (    [\n",
      "10                 [MSK]([aabb]))(baba)     (    (\n",
      "11           (cbb[MSK]babaaabbbabaabad)     a    a\n",
      "12           ((((ba))))([[[(ba)[MSK]]])     ]    ]\n",
      "13        [(((ccabababbababaab[MSK])))]     e    e\n",
      "14             [(cabd)([b[MSK]bababa])]     a    a\n",
      "15         ([cabbaabd])[cb[MSK]abaabad]     b    b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 4: 100%|██████████| 318/318 [00:57<00:00,  5.49it/s, loss=0.53] \n",
      "Train 5:   0%|          | 0/318 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  input label pred\n",
      "0                      (ab)[a[MSK]babb]     a    a\n",
      "1                  ((ab))[MSK]((baba)))     (    (\n",
      "2              (baabababbababaabb[MSK])     a    a\n",
      "3   [ccbaabbae](([MSK][bbabaa]]))(cabd)     [    e\n",
      "4   [[(ccababababe)][(ab[MSK]]((abab))]     )    ]\n",
      "5              ((ab[MSK]a)[([[cbad]])])     b    b\n",
      "6                    [MSK]cbad)[abbaab]     (    (\n",
      "7          (([cbbaabbb[MSK]aabbaabad]))     a    a\n",
      "8           ([ab][MSK][(ba)]([ccababe])     )    )\n",
      "9        [[MSK]ccaababbaabbe)(ccababe)]     (    (\n",
      "10                 [MSK]([aabb]))(baba)     (    (\n",
      "11           (cbb[MSK]babaaabbbabaabad)     a    a\n",
      "12           ((((ba))))([[[(ba)[MSK]]])     ]    ]\n",
      "13        [(((ccabababbababaab[MSK])))]     e    e\n",
      "14             [(cabd)([b[MSK]bababa])]     a    a\n",
      "15         ([cabbaabd])[cb[MSK]abaabad]     b    b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 5: 100%|██████████| 318/318 [00:57<00:00,  5.50it/s, loss=0.417]\n",
      "Train 6:   0%|          | 0/318 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  input label pred\n",
      "0                      (ab)[a[MSK]babb]     a    a\n",
      "1                  ((ab))[MSK]((baba)))     (    (\n",
      "2              (baabababbababaabb[MSK])     a    a\n",
      "3   [ccbaabbae](([MSK][bbabaa]]))(cabd)     [    e\n",
      "4   [[(ccababababe)][(ab[MSK]]((abab))]     )    )\n",
      "5              ((ab[MSK]a)[([[cbad]])])     b    b\n",
      "6                    [MSK]cbad)[abbaab]     (    (\n",
      "7          (([cbbaabbb[MSK]aabbaabad]))     a    a\n",
      "8           ([ab][MSK][(ba)]([ccababe])     )    )\n",
      "9        [[MSK]ccaababbaabbe)(ccababe)]     (    (\n",
      "10                 [MSK]([aabb]))(baba)     (    (\n",
      "11           (cbb[MSK]babaaabbbabaabad)     a    a\n",
      "12           ((((ba))))([[[(ba)[MSK]]])     ]    ]\n",
      "13        [(((ccabababbababaab[MSK])))]     e    b\n",
      "14             [(cabd)([b[MSK]bababa])]     a    a\n",
      "15         ([cabbaabd])[cb[MSK]abaabad]     b    b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 6: 100%|██████████| 318/318 [00:57<00:00,  5.49it/s, loss=0.333]\n",
      "Train 7:   0%|          | 0/318 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  input label pred\n",
      "0                      (ab)[a[MSK]babb]     a    a\n",
      "1                  ((ab))[MSK]((baba)))     (    (\n",
      "2              (baabababbababaabb[MSK])     a    a\n",
      "3   [ccbaabbae](([MSK][bbabaa]]))(cabd)     [    [\n",
      "4   [[(ccababababe)][(ab[MSK]]((abab))]     )    )\n",
      "5              ((ab[MSK]a)[([[cbad]])])     b    b\n",
      "6                    [MSK]cbad)[abbaab]     (    (\n",
      "7          (([cbbaabbb[MSK]aabbaabad]))     a    a\n",
      "8           ([ab][MSK][(ba)]([ccababe])     )    )\n",
      "9        [[MSK]ccaababbaabbe)(ccababe)]     (    (\n",
      "10                 [MSK]([aabb]))(baba)     (    (\n",
      "11           (cbb[MSK]babaaabbbabaabad)     a    a\n",
      "12           ((((ba))))([[[(ba)[MSK]]])     ]    ]\n",
      "13        [(((ccabababbababaab[MSK])))]     e    e\n",
      "14             [(cabd)([b[MSK]bababa])]     a    a\n",
      "15         ([cabbaabd])[cb[MSK]abaabad]     b    b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 7: 100%|██████████| 318/318 [00:57<00:00,  5.55it/s, loss=0.266]\n",
      "Train 8:   0%|          | 0/318 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  input label pred\n",
      "0                      (ab)[a[MSK]babb]     a    a\n",
      "1                  ((ab))[MSK]((baba)))     (    (\n",
      "2              (baabababbababaabb[MSK])     a    a\n",
      "3   [ccbaabbae](([MSK][bbabaa]]))(cabd)     [    e\n",
      "4   [[(ccababababe)][(ab[MSK]]((abab))]     )    )\n",
      "5              ((ab[MSK]a)[([[cbad]])])     b    b\n",
      "6                    [MSK]cbad)[abbaab]     (    (\n",
      "7          (([cbbaabbb[MSK]aabbaabad]))     a    a\n",
      "8           ([ab][MSK][(ba)]([ccababe])     )    )\n",
      "9        [[MSK]ccaababbaabbe)(ccababe)]     (    (\n",
      "10                 [MSK]([aabb]))(baba)     (    (\n",
      "11           (cbb[MSK]babaaabbbabaabad)     a    a\n",
      "12           ((((ba))))([[[(ba)[MSK]]])     ]    ]\n",
      "13        [(((ccabababbababaab[MSK])))]     e    e\n",
      "14             [(cabd)([b[MSK]bababa])]     a    a\n",
      "15         ([cabbaabd])[cb[MSK]abaabad]     b    b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 8: 100%|██████████| 318/318 [00:57<00:00,  5.50it/s, loss=0.216]\n",
      "Train 9:   0%|          | 0/318 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  input label pred\n",
      "0                      (ab)[a[MSK]babb]     a    a\n",
      "1                  ((ab))[MSK]((baba)))     (    (\n",
      "2              (baabababbababaabb[MSK])     a    a\n",
      "3   [ccbaabbae](([MSK][bbabaa]]))(cabd)     [    e\n",
      "4   [[(ccababababe)][(ab[MSK]]((abab))]     )    )\n",
      "5              ((ab[MSK]a)[([[cbad]])])     b    b\n",
      "6                    [MSK]cbad)[abbaab]     (    (\n",
      "7          (([cbbaabbb[MSK]aabbaabad]))     a    a\n",
      "8           ([ab][MSK][(ba)]([ccababe])     )    )\n",
      "9        [[MSK]ccaababbaabbe)(ccababe)]     (    (\n",
      "10                 [MSK]([aabb]))(baba)     (    (\n",
      "11           (cbb[MSK]babaaabbbabaabad)     a    a\n",
      "12           ((((ba))))([[[(ba)[MSK]]])     ]    ]\n",
      "13        [(((ccabababbababaab[MSK])))]     e    e\n",
      "14             [(cabd)([b[MSK]bababa])]     a    a\n",
      "15         ([cabbaabd])[cb[MSK]abaabad]     b    b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train 9: 100%|██████████| 318/318 [00:57<00:00,  5.50it/s, loss=0.193]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  input label pred\n",
      "0                      (ab)[a[MSK]babb]     a    a\n",
      "1                  ((ab))[MSK]((baba)))     (    (\n",
      "2              (baabababbababaabb[MSK])     a    a\n",
      "3   [ccbaabbae](([MSK][bbabaa]]))(cabd)     [    e\n",
      "4   [[(ccababababe)][(ab[MSK]]((abab))]     )    )\n",
      "5              ((ab[MSK]a)[([[cbad]])])     b    b\n",
      "6                    [MSK]cbad)[abbaab]     (    (\n",
      "7          (([cbbaabbb[MSK]aabbaabad]))     a    a\n",
      "8           ([ab][MSK][(ba)]([ccababe])     )    )\n",
      "9        [[MSK]ccaababbaabbe)(ccababe)]     (    (\n",
      "10                 [MSK]([aabb]))(baba)     (    (\n",
      "11           (cbb[MSK]babaaabbbabaabad)     a    a\n",
      "12           ((((ba))))([[[(ba)[MSK]]])     ]    ]\n",
      "13        [(((ccabababbababaab[MSK])))]     e    e\n",
      "14             [(cabd)([b[MSK]bababa])]     a    a\n",
      "15         ([cabbaabd])[cb[MSK]abaabad]     b    b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "global_step = 0.\n",
    "model = model.to(config.device)\n",
    "for epoch in range(config.n_epochs):\n",
    "    step, losses = 0, 0\n",
    "    p_bar = tqdm(dl_train, desc=f\"Train {epoch}\")\n",
    "    for tok_list, mask_idcs, mask_toks in p_bar:\n",
    "        tok_list = tok_list.to(config.device)\n",
    "        mask_toks = mask_toks.to(config.device)\n",
    "        mask_idcs = mask_idcs.to(config.device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(tok_list, mask_idcs)\n",
    "        loss = criterion(logits.transpose(1, 2), mask_toks) # for masked LM\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        step += 1\n",
    "        global_step +=1\n",
    "        losses += loss.item()\n",
    "        p_bar.set_postfix({'loss': losses / step})\n",
    "        \n",
    "        if global_step % config.freqs.print_valid_preds == 0:\n",
    "            with torch.no_grad():\n",
    "                logits = model(tok_list_vis.to(config.device), mask_idcs_vis.to(config.device))\n",
    "                preds_vis = logits.argmax(axis=2).cpu()\n",
    "            all_sentence, all_labels, all_preds = get_verbose_output(tok_list_vis, mask_toks_vis, preds_vis, ds_valid)\n",
    "            df = pd.DataFrame({'input': all_sentence, 'label': all_labels, 'pred': all_preds})\n",
    "            print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
