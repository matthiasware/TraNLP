{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4557c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723c3c3e",
   "metadata": {},
   "source": [
    "### TODO\n",
    "- Understand gathering in last layer\n",
    "- different loss?\n",
    "- padding mask is strange\n",
    "- What is my baseline?\n",
    "- What is the expected output?\n",
    "\n",
    "### Resources\n",
    "- https://github.com/codertimo/BERT-pytorch/\n",
    "- https://nlp.seas.harvard.edu/2018/04/03/attention.html\n",
    "- https://jalammar.github.io/illustrated-transformer/\n",
    "- https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial\n",
    "- https://arxiv.org/abs/1810.04805\n",
    "- https://neptune.ai/blog/unmasking-bert-transformer-model-performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f55b369",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import pickle\n",
    "from transformer.datasets import get_specialized_vocabulary, GrammarDataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from dotted_dict import DottedDict\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from transformer.utils import count_parameters\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce34eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DottedDict()\n",
    "config.n_vis = 16\n",
    "config.batch_size = 512     \n",
    "config.pred_min = 1               # min number of masked tokens [MSK]\n",
    "config.pred_max = 1               # max number of masked tokens\n",
    "config.pred_freq = 0.15           # number of mask tokens = pred_freq * d_l\n",
    "config.d_model = 8                # embed. dimension of tokens and positions\n",
    "config.d_k = 64           \n",
    "config.d_q = 64\n",
    "config.d_v = config.d_model\n",
    "config.d_ff = 3 * config.d_model\n",
    "config.n_heads = 4               # number of attention heads\n",
    "config.d_sentence = 32            # number of tokens in sentence\n",
    "config.n_layers = 2\n",
    "config.device = \"cuda:0\"\n",
    "config.p_data = Path(\"data\") / \"grammar-00.pkl\"\n",
    "config.n_epochs = 50\n",
    "config.lr = 0.001\n",
    "#\n",
    "config.freqs = DottedDict()\n",
    "config.freqs.print_valid_preds = 318 * 1   # steps\n",
    "config.freqs.eval = 1                      # epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456132fb",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a380936c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config.p_data, \"rb\") as file:\n",
    "    data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad49e76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data[\"data_train\"]\n",
    "data_valid = data[\"data_valid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0440e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_dict = get_specialized_vocabulary(data[\"vocabulary\"])\n",
    "print(tok_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32ce6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tok_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56add87",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = GrammarDataset(data[\"data_train\"], tok_dict, d_sentence=config.d_sentence)\n",
    "ds_valid = GrammarDataset(data[\"data_valid\"], tok_dict, d_sentence=config.d_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b635153",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(ds_train, batch_size=config.batch_size, shuffle=True, num_workers=8)\n",
    "dl_valid = DataLoader(ds_valid, batch_size=config.batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa07012e",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a2ac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformer.layers import Embedding, AttentionEncoder\n",
    "from transformer.utils import get_attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e66b5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "    def __init__(\n",
    "        self, d_vocab: int, d_model: int, d_sentence: int,\n",
    "        n_layers, n_heads, d_k, d_v, d_ff\n",
    "    ):\n",
    "        super(BERT, self).__init__()\n",
    "        #\n",
    "        self.d_vocab = d_vocab\n",
    "        self.d_model = d_model\n",
    "        self.d_sentence = d_sentence\n",
    "        self.n_layers = n_layers\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        self.d_ff = d_ff\n",
    "        #\n",
    "        assert self.d_v == self.d_model # not optimal but hey ...\n",
    "        \n",
    "        # Input Embeddings\n",
    "        self.embedding = Embedding(d_vocab, d_model, d_sentence)\n",
    "        \n",
    "        # Attention Layers\n",
    "        self.layers = []\n",
    "        for _ in range(n_layers):\n",
    "            layer = AttentionEncoder(d_model, d_k, d_v, n_heads, d_ff)\n",
    "            self.layers.append(layer)\n",
    "        self.layers = nn.ModuleList(self.layers)\n",
    "        \n",
    "        # Output Head\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.linear = nn.Linear(d_model, d_model)\n",
    "        self.gelu = torch.nn.GELU()\n",
    "        \n",
    "        # Output Decoder\n",
    "        #  = inverse Embedding\n",
    "        # There might be a better solution\n",
    "        self.decoder = nn.Linear(d_model, d_vocab)\n",
    "        self.decoder.weight = self.embedding.tok_emb.weight\n",
    "        self.decoder_bias = nn.Parameter(torch.zeros(d_vocab))\n",
    "    \n",
    "    \n",
    "    def forward(self, input_ids, input_mask_pos):\n",
    "        mask = get_attn_mask(input_ids)\n",
    "        out = self.embedding(input_ids)\n",
    "        for layer in self.layers:\n",
    "            out, attn = layer(out, mask)\n",
    "        \n",
    "        # [b, max_pred, d_model]\n",
    "        masked_pos = input_mask_pos[:, :, None].expand(-1, -1, out.size(-1))\n",
    "        h_masked = torch.gather(out, 1, masked_pos)\n",
    "        h_masked = self.norm(self.gelu(self.linear(h_masked)))\n",
    "        #\n",
    "        logits = self.decoder(h_masked) + self.decoder_bias\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ada678e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERT(d_vocab=len(tok_dict),\n",
    "             d_model=config.d_model,\n",
    "             d_sentence=config.d_sentence,\n",
    "             n_layers=config.n_layers,\n",
    "             n_heads=config.n_heads,\n",
    "             d_k=config.d_k,\n",
    "             d_v=config.d_v,\n",
    "             d_ff=config.d_ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af73568",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51216bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"#Params: {:,}\".format(count_parameters(model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768f4678",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618d51bd",
   "metadata": {},
   "source": [
    "### Vis data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de2cd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_data = next(iter(dl_valid))\n",
    "tok_list_vis, mask_idcs_vis, mask_toks_vis = next(iter(dl_valid))\n",
    "tok_list_vis = tok_list_vis[:config.n_vis]\n",
    "mask_idcs_vis = mask_idcs_vis[:config.n_vis]\n",
    "mask_toks_vis = mask_toks_vis[:config.n_vis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47ae75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(tok_list_vis.to(config.device), mask_idcs_vis.to(config.device))\n",
    "preds_vis = logits.argmax(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c81b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_verbose_output(tok_list, mask_toks, preds, grammar_ds):\n",
    "    #\n",
    "    all_sentences = []\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    #\n",
    "    for idx in range(preds.size(0)):\n",
    "        sentence = [grammar_ds.idx_dict[tok_id.item()] for tok_id in tok_list[idx] if tok_id.item() not in (0, 2)]\n",
    "        sentence = \"\".join(sentence)\n",
    "        all_sentences.append(sentence)\n",
    "        #\n",
    "        label = grammar_ds.idx_dict[mask_toks[idx].item()]\n",
    "        pred = grammar_ds.idx_dict[preds[idx].item()]\n",
    "\n",
    "        all_labels.append(label)\n",
    "        all_predictions.append(pred)\n",
    "\n",
    "    return all_sentences, all_labels, all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f92eda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentence, all_labels, all_preds = get_verbose_output(tok_list_vis, mask_toks_vis, preds_vis, ds_valid)\n",
    "right_pred = [p == l for p, l in zip(all_preds, all_labels)]\n",
    "df = pd.DataFrame({'input': all_sentence, 'label': all_labels, 'pred': all_preds, 'match': right_pred})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1142bbbe",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb51a831",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "global_step = 0.\n",
    "model = model.to(config.device)\n",
    "#\n",
    "all_accs = []\n",
    "all_train_losses = []\n",
    "all_valid_losses = []\n",
    "#\n",
    "for epoch in range(config.n_epochs):\n",
    "    step, losses = 0, 0\n",
    "    p_bar = tqdm(dl_train, desc=f\"Train {epoch}\")\n",
    "    \n",
    "    # TRAIN LOOP\n",
    "    for tok_list, mask_idcs, mask_toks in p_bar:\n",
    "        model.train()\n",
    "        tok_list = tok_list.to(config.device)\n",
    "        mask_toks = mask_toks.to(config.device)\n",
    "        mask_idcs = mask_idcs.to(config.device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(tok_list, mask_idcs)\n",
    "        loss = criterion(logits.transpose(1, 2), mask_toks) # for masked LM\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        step += 1\n",
    "        global_step +=1\n",
    "        losses += loss.item()\n",
    "        p_bar.set_postfix({'loss': losses / step})\n",
    "        \n",
    "        if global_step % config.freqs.print_valid_preds == 0:\n",
    "            with torch.no_grad():\n",
    "                logits = model(tok_list_vis.to(config.device), mask_idcs_vis.to(config.device))\n",
    "                preds_vis = logits.argmax(axis=2).cpu()\n",
    "            all_sentence, all_labels, all_preds = get_verbose_output(tok_list_vis, mask_toks_vis, preds_vis, ds_valid)\n",
    "            right_pred = [p == l for p, l in zip(all_preds, all_labels)]\n",
    "            df = pd.DataFrame({'input': all_sentence, 'label': all_labels, 'pred': all_preds, 'match': right_pred})\n",
    "            print(df)\n",
    "    all_train_losses.append(losses)\n",
    "    # EVAL LOOP\n",
    "    if epoch % config.freqs.eval == 0:\n",
    "        losses, accs, step = 0., 0., 0\n",
    "        p_bar = tqdm(dl_valid, desc=f\"Eval {epoch}\")\n",
    "        for tok_list, mask_idcs, mask_toks in p_bar:\n",
    "            tok_list = tok_list.to(config.device)\n",
    "            mask_toks = mask_toks.to(config.device)\n",
    "            mask_idcs = mask_idcs.to(config.device)\n",
    "            #\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                logits = model(tok_list, mask_idcs)\n",
    "                loss = criterion(logits.transpose(1, 2), mask_toks) # for masked LM\n",
    "                preds = logits.argmax(axis=2)\n",
    "                acc = (preds == mask_toks).sum() / preds.size(0)\n",
    "                #\n",
    "                losses += loss.item()\n",
    "                accs += acc.item()\n",
    "                step += 1\n",
    "                p_bar.set_postfix({'loss': losses / step, 'acc': accs / step})\n",
    "            all_valid_losses.append(losses)\n",
    "            all_accs.append(accs)\n",
    "        if (accs / step) >= 0.99:\n",
    "            print(\"Solved\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150f96b3",
   "metadata": {},
   "source": [
    "### Inspect Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af350f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() \n",
    "with torch.no_grad():\n",
    "    logits = model(tok_list_vis.to(config.device), mask_idcs_vis.to(config.device))\n",
    "    preds_vis = logits.argmax(axis=2).cpu()\n",
    "    all_sentence, all_labels, all_preds = get_verbose_output(tok_list_vis, mask_toks_vis, preds_vis, ds_valid)\n",
    "    right_pred = [p == l for p, l in zip(all_preds, all_labels)]\n",
    "    df = pd.DataFrame({'input': all_sentence, 'label': all_labels, 'pred': all_preds, 'match': right_pred})\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b06a00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tok_list_vis.to(config.device)\n",
    "mask = get_attn_mask(input_ids)\n",
    "#\n",
    "attentions = []\n",
    "with torch.no_grad():\n",
    "    emb = out = model.embedding(input_ids)\n",
    "    for layer in model.layers:\n",
    "        out, attn = layer(out, mask)\n",
    "        attentions.append(attn.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac30f4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 0\n",
    "print(all_sentence[sample_idx])\n",
    "atts = [attention[sample_idx].squeeze() for attention in attentions]\n",
    "#\n",
    "xtick_labels = [str(i) for i in list(tok_list_vis[sample_idx].numpy())]\n",
    "xtick_labels = [ds_valid.idx_dict[i] for i in list(tok_list_vis[sample_idx].numpy())]\n",
    "sentence = all_sentence[sample_idx]\n",
    "\n",
    "n_rows = len(atts)\n",
    "n_cols = config.n_heads\n",
    "#\n",
    "plt_scale = 12\n",
    "#\n",
    "figsize = (n_cols * plt_scale, n_rows * plt_scale)\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "for row_idx in range(n_rows):\n",
    "    for col_idx in range(n_cols):\n",
    "        if n_cols == 1:\n",
    "            ax = axes[row_idx]\n",
    "            attn = atts[row_idx]\n",
    "        else:\n",
    "            attn = atts[row_idx][col_idx]\n",
    "            ax = axes[row_idx][col_idx]\n",
    "        ax.imshow(attn)\n",
    "        #\n",
    "        #ax.set_title(sentence)\n",
    "        ax.set_xticklabels(xtick_labels)\n",
    "        ax.set_xticks(list(range(32)))\n",
    "        #\n",
    "        ax.set_yticks(list(range(32)))\n",
    "        ax.set_yticklabels(xtick_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f24d23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
