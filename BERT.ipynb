{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf25b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "from random import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from dotted_dict import DottedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ce27f2",
   "metadata": {},
   "source": [
    "### Resources\n",
    "- https://github.com/codertimo/BERT-pytorch/\n",
    "- https://nlp.seas.harvard.edu/2018/04/03/attention.html\n",
    "- https://jalammar.github.io/illustrated-transformer/\n",
    "- https://neptune.ai/blog/how-to-code-bert-using-pytorch-tutorial\n",
    "- https://arxiv.org/abs/1810.04805\n",
    "- https://neptune.ai/blog/unmasking-bert-transformer-model-performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63807d98",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de949328",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DottedDict()\n",
    "config.batch_size = 4     \n",
    "config.pred_min = 2      # min number of masked tokens [MSK]\n",
    "config.pred_max = 4      # max number of masked tokens\n",
    "config.pred_freq = 0.15  # number of mask tokens = pred_freq * d_l\n",
    "config.d_model = 8       # embed. dimension of tokens and positions\n",
    "config.d_k = 5           \n",
    "config.d_q = 5\n",
    "config.d_v = 8\n",
    "config.d_ff = 4 * config.d_model\n",
    "config.n_heads = 3       # number of attention heads\n",
    "config.d_l = 10          # number of tokens in sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dbd20e",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78285bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = (\n",
    "    \"baabaac\",\n",
    "    \"aababc\",\n",
    "    \"bcaaaa\",\n",
    "    \"aac\",\n",
    "    \"bbbaabbaa\",\n",
    "    \"bbbbbbabc\",\n",
    "    \"ababc\",\n",
    "    \"babc\",\n",
    "    \"bcaaca\",\n",
    "    \"aabbaaac\",\n",
    ")\n",
    "corpus_vocabuary = ('a', 'b', 'c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3496e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special Toks:\n",
    "#   [CLS]: Required to remove the 0 from positional meaning & use it to represent a sentence\n",
    "#   [PAD]: Required to standardize sequence length for batch processing\n",
    "#   [MSK]: Required to mask out the target prediction tokens in the input\n",
    "\n",
    "spec_tok_dict = {'[PAD]': 0, '[MSK]': 1, '[CLS]': 2}\n",
    "spec_idx_dict = {idx: word for word, idx in spec_tok_dict.items()}\n",
    "idx_dict = {}\n",
    "tok_dict = {}\n",
    "tok_list = []\n",
    "\n",
    "# word dict\n",
    "for tok, idx in spec_tok_dict.items():\n",
    "    tok_dict[tok] = idx\n",
    "for idx, tok in enumerate(corpus_vocabuary):\n",
    "    tok_dict[tok] = idx + len(spec_tok_dict)\n",
    "\n",
    "for tok, idx in tok_dict.items():\n",
    "    idx_dict[idx] = tok\n",
    "    tok_list.append(tok)\n",
    "\n",
    "d_vocabulary = len(tok_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de5e10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tok_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d4e21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spec_tok_dict)\n",
    "print(spec_idx_dict)\n",
    "print(idx_dict)\n",
    "print(tok_dict)\n",
    "print(tok_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ee5dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 0\n",
    "sentence = corpus[sample_idx]\n",
    "\n",
    "# sentence to idx vectors\n",
    "# -) tokenize\n",
    "tokens = list(sentence)\n",
    "\n",
    "# 2) replace with vocabulary idcs\n",
    "tok_list = [tok_dict[tok] for tok in tokens]\n",
    "tok_list = np.array(tok_list)\n",
    "\n",
    "# 3) calculate the number of predctions\n",
    "n_preds = int(round(len(tok_list) * config.pred_freq))\n",
    "n_preds = min(max(config.pred_min, n_preds), config.pred_max)\n",
    "\n",
    "# 4) create MASKS\n",
    "mask_idcs = np.random.choice(len(tok_list), size=n_preds, replace=False)\n",
    "mask_toks = tok_list[mask_idcs]\n",
    "tok_list[mask_idcs] = tok_dict[\"[MSK]\"]\n",
    "np.pad(mask_toks, (0, config.pred_max), mode=\"constant\")\n",
    "\n",
    "# 5) PAD\n",
    "n_pad = config.d_l - len(tok_list)\n",
    "tok_list = np.pad(tok_list, (1, n_pad - 1), mode='constant')\n",
    "\n",
    "# ADD CLS Token to start\n",
    "tok_list[0] = tok_dict['[CLS]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c15c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sentence:  \", corpus[sample_idx])\n",
    "print(\"sentence:  \", [idx_dict[idx] for idx in tok_list])\n",
    "print(\"mask idcs:  \", mask_idcs)\n",
    "print(\"mask toks: \", [idx_dict[idx] for idx in mask_toks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aba340",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tok_list)\n",
    "print([idx_dict[idx] for idx in tok_list])\n",
    "print(mask_idcs)\n",
    "print([idx_dict[idx] for idx in mask_toks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e652d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(sentences):\n",
    "    all_toks_list = []\n",
    "    all_mask_idcs = []\n",
    "    all_mask_toks = []\n",
    "    for sentence in sentences:\n",
    "        tokens = list(sentence)\n",
    "\n",
    "        # 2) replace with vocabulary idcs\n",
    "        tok_list = [tok_dict[tok] for tok in tokens]\n",
    "        tok_list = np.array(tok_list)\n",
    "\n",
    "        # 3) calculate the number of predctions\n",
    "        n_preds = int(round(len(tok_list) * config.pred_freq))\n",
    "        n_preds = min(max(config.pred_min, n_preds), config.pred_max)\n",
    "\n",
    "        # 4) create MASKS\n",
    "        # UNDERCOMPLETE: The whole process is explained here:\n",
    "        # https://neptune.ai/blog/unmasking-bert-transformer-model-performance\n",
    "        mask_idcs = np.random.choice(len(tok_list), size=n_preds, replace=False)\n",
    "        mask_toks = tok_list[mask_idcs]\n",
    "        tok_list[mask_idcs] = tok_dict[\"[MSK]\"]\n",
    "        # add 1 to mask idxs since we added one position in the front\n",
    "        mask_idcs += 1\n",
    "        mask_idcs = np.pad(mask_idcs, (0, config.pred_max), mode=\"constant\")\n",
    "\n",
    "        # 5) PAD\n",
    "        n_pad = config.d_l - len(tok_list)\n",
    "        tok_list = np.pad(tok_list, (1, n_pad - 1), mode='constant')\n",
    "\n",
    "        # ADD CLS Token to start\n",
    "        tok_list[0] = tok_dict['[CLS]']\n",
    "        \n",
    "        all_toks_list.append(tok_list)\n",
    "        all_mask_idcs.append(mask_idcs)\n",
    "        all_mask_toks.append(mask_toks)\n",
    "        \n",
    "    return all_toks_list, all_mask_idcs, all_mask_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0a9185",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = get_batch(corpus[:config.batch_size])\n",
    "all_toks_list, all_mask_idcs, all_mask_toks  = map(torch.LongTensor, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eace08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_toks_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8c5be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mask_idcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1767620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mask_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93008c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for toks in all_toks_list:\n",
    "    print([idx_dict[idx.item()] for idx in toks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eb2d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus[:config.batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3666cd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mt in all_mask_toks:\n",
    "    print([idx_dict[idx.item()] for idx in mt])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2237640",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea695722",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self, d_vocabulary, d_model, d_l):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.d_vocabulary = d_vocabulary\n",
    "        self.d_model = d_model\n",
    "        #\n",
    "        self.tok_emb = nn.Embedding(d_vocabulary, d_model)  # token embedding\n",
    "        self.pos_emb = nn.Embedding(d_l, d_model)  # position embedding\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len = x.size(1)\n",
    "        pos = torch.arange(seq_len, dtype=torch.long)\n",
    "        pos = pos.unsqueeze(0).expand_as(x)  # (seq_len,) -> (batch_size, seq_len)\n",
    "        embedding = self.tok_emb(x) + self.pos_emb(pos)\n",
    "        return self.norm(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9031a10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_emb = Embedding(d_vocabulary, config.d_model, config.d_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324b6a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = model_emb(all_toks_list)\n",
    "assert emb.shape == torch.Size((config.batch_size, config.d_l, config.d_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8be7170",
   "metadata": {},
   "source": [
    "### Attention Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf85b4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_pad_mask_orig(seq_q, seq_k):\n",
    "    batch_size, len_q = seq_q.size()\n",
    "    batch_size, len_k = seq_k.size()\n",
    "    # eq(zero) is PAD token\n",
    "    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1)  # batch_size x 1 x len_k(=len_q), one is masking\n",
    "    return pad_attn_mask.expand(batch_size, len_q, len_k)  # batch_size x len_q x len_k\n",
    "\n",
    "def get_attn_pad_mask(x):\n",
    "    mask = x.eq(0).unsqueeze(1).repeat(1, x.size(1), 1).unsqueeze(1)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9f7544",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_mask = get_attn_pad_mask_orig(all_toks_list, all_toks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62867ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(attn_mask.shape)\n",
    "print(emb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55447ba",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f16352",
   "metadata": {},
   "source": [
    "#### Attention Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af518098",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, d_k):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "        self.d_k = d_k\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        # without heads:\n",
    "        # Q (d_b, d_l, d_k)\n",
    "        # K (d_b, d_l, d_k)\n",
    "        # V (d_n, d_l, d_v)\n",
    "        # attn_mask (d_b, d_l, d_l)\n",
    "        #\n",
    "        # scores = (d_b, d_l, d_l)\n",
    "        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(self.d_k)\n",
    "        scores.masked_fill_(attn_mask, -1e9) # Fills elements of self tensor with value where mask is one.\n",
    "        attn = nn.Softmax(dim=-1)(scores)\n",
    "        \n",
    "        # context = (d_b, d_l, d_v)\n",
    "        context = torch.matmul(attn, V)\n",
    "        return context, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c603eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(attn_mask.shape)\n",
    "attn_mask_headed = attn_mask.unsqueeze(1).repeat(1, config.n_heads, 1, 1)\n",
    "print(attn_mask_headed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e898f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# without dimension for heads\n",
    "#\n",
    "Q = torch.rand((config.batch_size, config.d_l, config.d_k))\n",
    "K = torch.rand((config.batch_size, config.d_l, config.d_k))\n",
    "V = torch.rand((config.batch_size, config.d_l, config.d_v))\n",
    "#\n",
    "attn_mask = get_attn_pad_mask_orig(all_toks_list, all_toks_list)\n",
    "#\n",
    "model_sdpa = ScaledDotProductAttention(config.d_k)\n",
    "context, attn = model_sdpa(Q, K, V, attn_mask)\n",
    "#\n",
    "assert context.shape == torch.Size((config.batch_size, config.d_l, config.d_v))\n",
    "assert attn.shape == torch.Size((config.batch_size, config.d_l, config.d_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d57498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with dimension for heads\n",
    "#\n",
    "Q = torch.rand((config.batch_size, config.n_heads, config.d_l, config.d_k))\n",
    "K = torch.rand((config.batch_size, config.n_heads, config.d_l, config.d_k))\n",
    "V = torch.rand((config.batch_size, config.n_heads, config.d_l, config.d_v))\n",
    "#\n",
    "attn_mask = get_attn_pad_mask_orig(all_toks_list, all_toks_list)\n",
    "attn_mask_headed = attn_mask.unsqueeze(1).repeat(1, config.n_heads, 1, 1)\n",
    "#\n",
    "model_sdpa = ScaledDotProductAttention(config.d_k)\n",
    "context, attn = model_sdpa(Q, K, V, attn_mask_headed)\n",
    "#\n",
    "assert context.shape == torch.Size((config.batch_size, config.n_heads, config.d_l, config.d_v))\n",
    "assert attn.shape == torch.Size((config.batch_size, config.n_heads, config.d_l, config.d_l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db66e36a",
   "metadata": {},
   "source": [
    "### Sublayer Residual connection + Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1d1c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormedResidualSubLayerConnection(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super(NormedResidualSubLayerConnection, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "    \n",
    "    def forward(self, x, sublayer):\n",
    "        return x + sublayer(self.norm(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe178f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_res = NormedResidualSubLayerConnection(config.d_model)\n",
    "sublayer = lambda x: x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a894fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape)\n",
    "out = model_res(x, sublayer)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d262c9",
   "metadata": {},
   "source": [
    "#### Multihead Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12f8e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, d_k, d_v, n_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        #\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        #\n",
    "        self.W_Q = nn.Linear(d_model, d_k * n_heads)\n",
    "        self.W_K = nn.Linear(d_model, d_k * n_heads)\n",
    "        self.W_V = nn.Linear(d_model, d_v * n_heads)\n",
    "        #\n",
    "        self.model_sdpa = ScaledDotProductAttention(d_k)\n",
    "        self.output_linear = nn.Linear(n_heads * d_v, d_v)\n",
    "        \n",
    "        # here d_v == d_model\n",
    "        # rework this module to be independent of the dimensions \n",
    "        # or simplify the dimensions\n",
    "        self.output_norm = nn.LayerNorm(d_v)\n",
    "        \n",
    "    def forward(self, x, attn_mask):\n",
    "        # x         (b, d_l, d_model) = (b, s, m)\n",
    "        # attn_mask (b, d_l, d_model)\n",
    "        #\n",
    "        d_b = x.size(0)\n",
    "        #\n",
    "        # (b, s, m) x (h, m, k) -> (b, h, m, k)\n",
    "        q_s = self.W_Q(x).view(d_b, -1, self.n_heads, self.d_k).transpose(1,2)\n",
    "        k_s = self.W_K(x).view(d_b, -1, self.n_heads, self.d_k).transpose(1,2)\n",
    "        \n",
    "        # (b, s, m) x (h, m, v) -> (b, h, m, k)\n",
    "        v_s = self.W_V(x).view(d_b, -1, self.n_heads, self.d_v).transpose(1,2)\n",
    "        \n",
    "        # (b, l, l) -> (b, h, l, l)\n",
    "        attn_mask_headed = attn_mask.unsqueeze(1).repeat(1, self.n_heads, 1, 1)\n",
    "        \n",
    "        context, attn = self.model_sdpa(q_s, k_s, v_s, attn_mask_headed)\n",
    "        \n",
    "        # (b, h, l, v) -> (b, l, h * v)\n",
    "        context = context.transpose(1, 2).contiguous().view(d_b, -1, self.n_heads * self.d_v)\n",
    "        \n",
    "        # (b, l, h*v) - > (b, l, v)\n",
    "        output = self.output_linear(context)\n",
    "        \n",
    "        # (b, l, v) -> (b, l, v) where v == d_model right now\n",
    "        output = self.output_norm(x + output)\n",
    "        return output, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff705bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mha = MultiHeadAttention(config.d_model, config.d_k, config.d_v, config.n_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3519455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output, attn = model_mha(x, attn_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1276de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.shape)\n",
    "print(attn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e8f0b8",
   "metadata": {},
   "source": [
    "### Position Wise Feed Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb62202",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    \"\"\"\n",
    "    Paper Section 3.4, last paragraph notice that BERT used the GELU instead of RELU\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))\n",
    "        #return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
    "\n",
    "class PoswiseFeedForwardNet(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.gelu = GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (b, l, m) -> (b, l, d_ff) -> (b, l, m)\n",
    "        out = self.fc1(x)\n",
    "        out = self.gelu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a6708c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
